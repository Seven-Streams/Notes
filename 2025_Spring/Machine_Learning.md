# Machine Learning

## Lec1 机器学习简介

什么是 AI?

#### 数据科学

已知联合概率分布 $p(x_1,x_2)$，设法找到条件分布 $p(x_2|x_1)$

LM:  $p(x)=\prod_{i=1}^T p_\theta(x|x_0,...,x_T)$

从 LM 到 LLM

有价值的是数据产生的服务。

#### 机器学习的定义

智能的本质在于学习。

ANI, AGI, ASI

机器学习研究的是学习算法。由三元组 <T, P, E> 明确定义。 T 为某些任务， E 为经验， P 为性能。

什么时候机器学习具有优势？

两种机器学习的类型：预测和决策。

预测：

- 监督学习，根据数据预测所需的输出。

- 无监督学习，生成数据实例。

决策：强化学习，在动态环境中采取行动。

2012 AI 的崛起

#### 机器学习的应用

预测任务，生成任务，决策任务。

#### 机器学习基本思想

监督学习，无监督学习，强化学习

监督学习：

给定带标签的训练数据集 $D=\{(x_i,y_i)\}_{i\in[n]}$, $x_i$ 是特征数据， $y_i$ 是对应的标签。学习的是对应的映射 $y_i\simeq f_\theta(x_i)$, 我们把 $\{f_\theta(·)\}$ 称为假设空间。学习的过程，也就是对参数的更新。

学习的想法：预测的结果尽量接近。即 $\min_\theta\frac 1N\sum_{i=1}^N\mathcal{L}(y_i,f_\theta(x_i))$

比较常见的还是均方误差 $\frac12(y_i-f_\theta(x_i))^2$， $1/2$ 还是为了梯度更好计算。并且容忍小误差，惩罚更大的误差。损失函数选择平方的原因，还是为了惩罚更远的错误。

梯度学习方法

使用不同的模型，实际上就是在修改不同的假设空间。

#### 模型选择

##### 欠拟合和过拟合

under-fitting, over-fitting

泛化

##### 正则化

添加对参数的惩罚项。即 $\min_\theta\frac 1N\sum_{i=1}^N\mathcal{L}(y_i,f_\theta(x_i))+\lambda\Omega(\theta)$

Proposed Model 最好能力较强。因为能力差是没法解决的。但正则化(regularization)可以帮助解决问题。

比较经典的正则化方式：

- L2 正则化(岭回归 Ridge): $\Omega(\theta)=\sum_m\theta_m^2$

- L1正则化(拉索回归 LASSO): $\Omega(\theta)=\sum_m|\theta_m|$,倾向于会让一些参数降为 0 。


