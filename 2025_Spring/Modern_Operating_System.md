# 现代操作系统

## 第一章 引论

内核态和用户态：操作系统运行在内核态，对所有硬件有完全访问权。

操作系统有两个功能：

- 提供抽象

- 管理硬件（主要是多路复用，包括时间和空间）

大多数总线都是共享总线架构。因此，需要通过仲裁器决定谁使用总线。

PCIe 总线取代了之前的 PCI 总线。PCIe 采用串行总线架构，而 PCI 采用并行总线架构。

这里所谓的串行，指的是单个数据是串行传输的；并行指的是单个数据通过多个数据通路发送，这对精确性等要求高，时延长。PCIe 的时延更短。

### 操作系统的基本概念

**进程**(process)：本质上是一个程序。进程有对应的**地址空间**(address space, 亦被称为 core image)。进程中包括一个程序计数器，寄存器等等。

和进程相关的所有信息，都会存在操作系统的一张表中，即**进程表**(process table)中。

进程间通信：interprocess communication.

工作目录(working directory): 每个进程有一个工作目录。若没有给出绝对地址，那么会在该目录下寻找。

文件描述符(file descriptor): 打开文件后检查其权限。如果权限许可，那么返回一个小整数。这个整数称为文件描述符。

管道(pipe): 一种虚文件。连接两个进程。

rwx 位

进程标识符(Process IDentifier, PID). fork() 父进程返回值为子进程 PID, 子进程返回值为 0.

mount 调用可以把目录挂载到别的位置下面。

## 第二章 进程与线程

### 进程

守护进程(daemon): 在后台停留的进程。当请求到达时唤醒并进行处理。

进程创建：系统初始化，系统调用 fork() 等。

父进程和子进程具有不同的地址空间。有时也会共享。此时为 copy on write.

进程退出：可能是自愿退出(无论是正常退出还是出错退出)；也可能是非自愿退出(严重错误，或者被其他进程杀死)。

UNIX 中，每一个进程都和它所有的子进程组成一个进程组。 init 进程会在系统初始化时被拉起。所有进程都可以看做是 init 进程的后裔进程。

在 Windows 中，进程的继承关系就可以被转移。父进程通过**句柄**与子进程交互。但其一旦把句柄转给另一个进程，继承关系就被转移。

进程的状态：

- 运行态

- 就绪态(可以运行，但是 CPU 被占用)

- 阻塞态

调度程序需要对不同状态的进程的处理进行转移。

进程表：每个进程占用一个进程表项。保证该进程可以直接从阻塞态和就绪态转移到运行态。

interrupt vector

多道程序设计： CPU 利用率 $= 1-p^n$

### 线程

传统中，一个进程包含一个地址空间和一个控制线程。在一个地址空间下，准并行地执行多个控制线程。

线程的好处：

- 利于通信

- 易于创建和摧毁

- 如果多个线程并非 CPU 密集型任务，那么就可以提高效率

线程之间也会不断切换，从而看上去在并行执行。比如 PC, 寄存器, 堆栈, 状态都会由线程来保存。

每个进程也应该存有一份线程表。

两种线程实现方式：在用户空间中和在内核中实现。

如果线程在用户空间中实现，那么内核只需要像单线程进程那样就可以了。

如果线程在内核中实现，那么线程的创建与摧毁也需要进行系统调用。需要与线程有关的调用都不得不进行系统调用。

还有一种方式是尝试进行混合的实现。

多个用户级线程对应一个内核线程。具体多少都由程序员。

### 进程间通信(IPC)

竞争条件(race condition)

临界区(critical region, critical section)

需要阻止对共享内存的同时读写：互斥(mutual exclusion)

- 中断屏蔽

- 自旋锁:自旋过程中 CPu 的空转称为忙等待(busy waiting). 这种策略只适合于等待时间较短的情况。不然性能浪费严重。

- Peterson 算法

- TSL(test and set lock)执行 TSL 后的 CPU 会锁住内存总线，并且禁止其他 CPU 在本指令结束之前访问内存。

- XCHG

信号量、互斥量、条件变量

屏障(barrier):可以用于进行一组线程的同步。直到所有要求的线程都达到了屏障，才会一起被释放。

无锁化：读-复制-更新(Read-Copy-Update, RCU).在一定的宽限期后，旧数据才不再可能被读到。

### 调度

- 计算密集型任务

- I/O密集型任务

三种不同的环境：

- 批处理

- 交互式

- 实时

不同的环境的要求不同。比如，批处理环境追求更高的 CPU 利用率。交互式环境要求最小的响应时间。实时环境要求来到的请求尽量满足截止时间。

#### 批处理环境

- first-come, first-served

- shortest job first

- shortest remaining time next

#### 交互环境

- round robing（轮转调度，但上下文切换也需要时间）

- 优先级调度

- CTSS(Compatible Time Sharing System, 多级队列，每次运行后下移优先级，但是分配的时间片长度翻倍)

- 最短进程优先

- 保证调度(尽量保证一定的性能)

- lottery scheduling(彩票调度，摇奖，可以给更重要的进程更高的优先级)

- 公平调度，每个用户分配到的 CPU 时间相同

#### 实时环境

- hard real time(硬实时，必须达到 DDL)

- soft real time(软实时，允许偶尔错失 DDL)

进程进行了 fork 之后，需要注意 wait. 防止产生 zombie(死了没人收尸)。父进程死了，还活着就是 orphan; 死了就是 zombie.

## 第三章 内存管理

把物理地址直接暴露给进程是非常危险的。因此，需要地址空间这种存储器抽象。

每个进程都有一份自己的地址空间。实现方式是动态重定位，也就是把每个进程的地址空间映射到不同的实际物理内存。

Problem: 每个进程拥有不同的地址空间，是非常消耗内存的行为。

两种解决方法：

- 交换(swapping): 进程切换时把当前地址空间中的内容存回磁盘。

- Virtual Memory

交换时，不必存储那些没有用到的内存！

如何跟踪分配内存的使用情况？

- 位图(给一定大小的数据块打上 0-1标记)

- 空闲区链表(利用各种适配算法去分配内存)

### 虚拟内存

每个程序拥有自己的地址空间。该空间被分割成多个块，称为页(page)。一页上的地址范围是连续的。

程序产生的地址都是虚拟地址，并且构成了一个虚拟地址空间！虚拟地址不会送内存总线上，而是送到内存管理单元(Memory Management Unit, MMU)上。

页在物理内存中的对应被称为页框(page frame).

为了有效判断一个 page 是否在内存中，会采用一个 present/absent bit 来记录页面是否在内存中。如果 MMU 发现其不在内存中，那么就会产生 page fault. 需要将其换入内存。

一般而言，采取页号作为页表的内存。

页表：每一个页表项由多个部分组成：页框号，脏位(dirty bit), present/absent bit, 保护位，访问位，允许高速缓存位。

我们不希望这个过程由很大的开销。需要加速分页的过程。

一种方式是转换检测缓冲区(Translation Lookaside Buffer, TLB, 快表)。其通常在 MMU 中，拥有更少的表项。实际上就可以看作是页表的一份缓存。

我们称页在内存中，而不在 TLB 中的情况为软失效(soft miss); 页不在内存中的情况为硬失效(hard miss). 无论哪一种，我们都需要进行页表遍历。

- 次要缺页错误(页在内存中，但是页表中没有记录)

- 严重缺页错误(页不在内存中)

- 段错误(访问非法地址)

针对大内存的页表，我们也有两种处理方式：

- 多级页表

- 倒排页表(由页框去对应页表项，而不是页本身去对应页表项)

处理缺页中断时，我们如何进行页面置换？

- 最优置换，淘汰之后最远会被用到的页。这是理想情况，不能实现。

- NRU(Not Recently Used):随机淘汰一个在最近一段时间未使用的页表。

- FIFO(无需赘述，但效果不好)

- Second Chance, 在 FIFO 的基础上，如果一张页加入内存后第一次出队，那么把这张页重新入队，并且重新进行出队操作。对每一页而言，直到第二次出队，才被真正换出。

- Clock, 实际上和 Second Chance 没有太大的区别。

- LRU(Least Recently Used)

- NFU(Not Frequently Used)，每一个页拥有一个计数器。每次时钟中断进行一次扫描，检查它们是否被访问。如果是，则计数器加一。换出访问最不频繁的页。

- 老化(Aging) 算法，在 NFU 的基础上，改为计数器右移一位，然后最高位设为 1. 其他一致。

- 工作集页面置换，称进程需要的所有页面为工作集。设法在进程运行之前，其工作集已在内存中，即预先调页(prepaging).发生缺页中断时，淘汰不在工作集中的一页。

- WSClock(工作集时钟).类似于工作集页面置换和 Clock 的结合。

### 分页系统的设计问题

我们称一个程序每执行几条指令就发生一次缺页中断的情况为颠簸。

缺页中断时，选择本进程的页进行淘汰，还是在全局上进行考虑？即：进行局部(local)页面置换，还是全局(global)页面置换。

全局的置换，通常效果会更好一些。并且，我们也给每一个进程规定一个最小的页框数，保证有这些内容在内存中。目前的一种方式是 PFF(page fault frequency, 缺页中断率)算法。控制分配给每一个进程的页框数。

负载控制：当 PFF 过高时，可以考虑把一些进程交换到磁盘中，并且释放其所有页面。

页面大小也需要进行一定的考虑。

指令空间可以考虑和地址空间分离。

部分内存中的页面也可以进行共享。

使用动态链接库

内存映射文件

如果发生缺页中断，那么我们可以进行一次上下文切换，进行别的工作，直到传输完成。

内存分段(segment).每个段的地址都是从 0 开始。这样可以为不同段一起设置不同的保护权限，并且有助于数据共享。

## 第四章 文件系统

### 文件

对于所有操作系统中，都有着普通文件(regular file) 和目录(directory) 两种文件。目录是一种管理文件结构的系统文件。

UNIX: Everything is a file.

普通文件分为 ASCII 文件和二进制文件两种。

二进制可执行文件头会有一个 magic number(魔数)，用来表征这个文件是一个可执行的二进制文件。

早期的操作系统只能进行顺序访问(sequential access).但是随着发展，有了随机访问文件(random access file).

文件也拥有着一定的属性(attribute).

文件操作需要系统调用来协助处理。比如 `create, delete, open, close, read, write, append, seek, get attributes, set attributes, rename`等等。

根目录：所有的目录可以构成一棵树。这棵树的根就是根目录。路径名一般会用两种方式来指明文件名。即绝对路径名(absolute path name) 和相对路径名(relative path name). 相对路径名是从工作目录(working directory) 开始的。

'.' 表示当前目录， ".." 表示父目录。

目录的操作也包含多种系统调用。如 `create, delete, opendir, closedir, readdir, rename, link, unlink` 等等。unlink 就是删除一个目录项。如果一个文件只在该目录中，那么这个文件就会被删除。

link 产生的是一种硬链接。

还有一种方式称为符号链接，即软链接。也就是创造一个文件，其中包含了一个绝对路径。

### 文件系统的实现

文件系统存放在磁盘上。每个分区中存在一个独立的文件系统。磁盘中的 0 号扇区被称为主引导记录(Master Boot Record, MBR), 其用来引导计算机。 MBR 的结尾是分区表，用来表示每个分区的起始位置和结束位置。

计算机引导时，BIOS 会读入并且执行 MBR. MBR 会确定活动分区，并且读入活动分区第一个块(引导块，boot block)并且进行执行。活动分区，也就是计算机的系统分区。

文件系统中，也有的是从超级块(super block)开始。超级块中包含文件系统中的一些关键参数，比如魔数是什么，文件系统中的块数量有多少，等等。

#### 文件的实现方案

- 连续分配？好处是实现简单，读性能好。但是删除文件后，磁盘空间会非常零碎。

- 链表分配？这样可以充分的利用磁盘空间，但是问题是随机访问速度慢，指针占掉了很多空间。

- 采用一张表！也是进行链表，但是不是在磁盘上构造，而是在内存中抽象地构造一张。内存中这样的表被称为文件分配表(FAT).

- index-node(i 节点)，列出了一个文件的文件属性和所有磁盘块的地址。它的好处在于只有在需要使用这个文件的时候才需要读入内存。

#### 目录的实现方案

两种方案：

- 简单实现，直接包含一个固定的文件名和文件实行。

- 文件名后只引用对应的 i-node.

如果采用共享文件的情况，那么可能会有多个目录指向同一个文件。这样的联系被称为链接，文件结构就变成了一个有向无环图(DAG).

日志结构的文件系统(Log-structured File System, LFS)，采用了一种完全不同的文件系统。

日志文件系统(重新启动后，可以通过查看日志，获取崩溃前计划完成的任务并且完成之)

虚拟文件系统(Virtual File System,VFS):把所有的文件系统统合在一个文件系统下。VFS 对所有的用户进程都有一套统一的上层接口，即 POSIX 接口。

#### 文件系统的管理和优化

所有的文件系统基本都把文件按照块来进行存储。选择块的大小是一件很重要的事。

记录空闲块的方式：块状链表来存储空闲块 or 采取位图。

磁盘强制配额：不允许某些文件拥有太多的磁盘空间、

文件系统也需要考虑备份，即容灾能力。物理转储和逻辑转储。

文件系统的一致性

为了提升性能，有这样的几种方式：

- 块高速缓存(block cache) 或 缓冲区高速缓存(buffer cache)。逻辑上都是磁盘的一部分，但实际上存在内存中。

- 块提前读

- 减少磁盘臂运动：把可能顺序访问的块放在一个柱面上等等。

## 第五章 输入/输出

I/O 设备可以分为两种：块设备(block device, 如硬盘，U盘等等)和字符设备(character device,键盘，鼠标等等).

I/O 设备一般也由机械部件和电子部件两部分组成。电子部件被称作为设备控制器(device controller)或者适配器(adapter).机械部件则是设备的本身。设备控制器和设备之间的接口通常是一个很低的接口。每个设备控制器被分配为一个 I/O端口号。用来和 CPU 进行通信。

现在也许更多的都是采用直接存储器存取(Direct Memory Access, DMA)的方式。CPU 通过总线和内存，IO 设备相连。 DMA 可以独立于 CPU 去访问内存总线。

DMA 的作用是把 IO设备的数据传输到存储器中。

1. CPU 通知 DMA 该把数据传输到哪里。

2. DMA 控制器在总线上发起一个读请求到磁盘控制器，发起 DMA 传送。

3. 磁盘控制器将数据写入内存。

4. 写操作完成后，其发给 DMA 一个应答信号。

DMA 控制器也可通过每次一字和块模式两种模式来进行操作。

DMA 一字模式下， CPU 由于总线被占用，如果想使用总线，则必须进行等待。这种机制被称为周期窃取(cycle stealing). 块模式下，则会进行大量的传输。被称为突发模式(burst mode).

I/O 软件需要有设备的独立性。这一点需要考虑统一命名(uniform naming).

精确中断的性质：

- PC 保存在一个已知的位置。

- 所有 PC 前的指令被执行完毕。

- 所以 PC 后的指令未执行。

- PC 指向的指令的执行状态已知。

同步问题？错误处理？缓冲问题？

- 程序控制的I/O

- 中断驱动的I/O

- 使用 DMA 的I/O

I/O 软件通常由四个层次组成：

1. 中断处理程序

2. 设备驱动程序

3. 与设备无关的I/O软件(这里用于向用户层提供一个设备驱动程序的统一接口，并且提供缓冲，错误报告，分配和释放专用设备，提供和设备无关的块大小等等)

4. 用户级的 I/O 软件

假脱机(spooling)技术：使得某一个进程开始独占该 I/O 设备。或者是通过守护进程(daemon)去管理假脱机目录(spooling directory)下的文件。通过这种方式，类似于给 IO 设备提供了更多的一层抽象。避免了不必要的长时占用。

### 盘

如磁盘，光盘，固态硬盘等等。

RAID(Redundant Array of Independent Disk)

磁盘的扇区由前导码，数据， ECC(纠错码)三部分组成。

考虑到如果扇区如果编号在相邻位置，那么当前一个块复制完毕后，由于检验纠错码需要时间，我们必须要等机械臂旋转一圈之后才能复制下一个块。为了解决这个问题，我们采用单交错或者双交错的方式，用这种编号方式来提高效率。

读写磁盘块的时间：

- seek time

- rotation delay

- actual data transfer time

FCFS(First-Come, First-Served) 这种方式很平凡，但不易优化。

一种调度算法是最短寻道优先(SSF, Shortest Seek First),总是处理和当前磁头距离最近的请求。

为了保证每个请求早晚都可以解决，我们有电梯算法(Elevaroe algorithm).即磁头按一个方向移动(up, down)，直到该方向上的请求全部处理完成。

如果扇道中有一个扇区出错了，那么一般而言，该扇道上的备用扇区就会替换为该扇区。

#### 稳定存储器

由一对全同的磁盘组成。它们总能读出相同结果。

- 稳定写：先写在驱动器 1 上。然后检查 1 上的结果。如果通过校验，那么修改驱动器 2.否则重复 n 次。如果超过 n 次，则启用备用块。

- 稳定读：先堵在驱动器 1 上。检查 ECC. 如果错误，再读 n 次。如果 ECC 总是不正确，那么读 2 的数据。

- 崩溃恢复(crash recovery): 检查两盘上的对应位置。如果都是好块并且相同，那么什么都不做。如果一好一坏，则用好的覆写坏的。如果都是好块但是不同，那么把 1 上的数据覆写 2.

### 时钟

时钟硬件一般用晶体振荡器去做。计数器会随着时钟每一次脉冲而减少。

时钟软件则是进行除了根据已知的时间间隔产生中断外的大多数任务。

还有所谓的软定时器。避免中断，并且是在内核态的情况下。

### 用户界面

键盘，文本窗口，X窗口系统(X Window System) , GUI 等等。

### 瘦客户机(thin client)

即以 PC 为中心的计算转移为了以 web 为中心的计算。

### 电源管理

Windows 系统有一个进行电源管理的精巧机制，称为 ACPI(Advanced Configuration and Power Interface, 高级配置与电源接口)。通过 ACPI, 操作系统可以向仍和符合标准的驱动程序发出命令，并且令其报告情况，甚至也可以令其削减功率水平。

## 第六章 死锁

有些资源是不可抢占的！

1. 请求资源

2. 使用资源

3. 释放资源

这是需要资源的一个常规顺序。

死锁的定义：一组进程中的每个进程都在等待其他进程才能完成的事件！

死锁发生的四个条件：

- 互斥

- 占有和等待

- 不可抢占

- 环路等待

### 鸵鸟算法

我更愿意称这种算法为苏联算法。

假装什么问题都没有就好了。说不定 bug 之后就不触发了。

### 死锁检测和死锁恢复

在这里，我们允许死锁的发生。但是死锁一旦发生，我们就会马上想办法去恢复。

我们可以通过构建一张资源分配图，然后检查这张图上是否有环来解决这个问题。

如果每种类型我们具有多个资源，这时的死锁检测可以采取矩阵方式检查。

死锁恢复主要有三种方式：

- 抢占。临时将某个资源的所有权进行转移。

- 回滚。回到上一个正常的检查点。并且把某个资源的所有权转移。

- 杀死进程。

### 死锁避免

通过资源轨迹图，我们可以直观地看到哪些地方是不安全的。

对于一个状态，如果存在一种资源的调度方案，使得每个进程都能够正常执行，那么我们就称这个状态为安全状态。反之，则为不安全状态。

银行家算法：判断某个进程申请资源后，是否会处于不安全状态。如果不安全，则不允许给出资源。

### 死锁预防

考虑破坏四个条件。前三个条件都是比较难以破坏的，因此我们只得考虑第四个条件。比如说，我们可以考虑给资源进行编号，必须从小到大地获得锁的顺序。

其他的一些问题：通信死锁，活锁等等。

## 第七章 虚拟化和云

虚拟机监控程序(hypervisor, VMM)需要解决三个问题：

- 安全性(Safety)

- 保真性(Fidelity)

- 高效性(Efficiency)

目前的 VMM 可以粗略分为两种类型。

- Type 1 hypervisor, 唯一一个运行在最高特权级的程序。支持多个虚拟机。

- Type 2 hypervisor, 运行在宿主操作系统(host operating system)上。向上支持其他客户操作系统(guest operating system)。

### 高效虚拟化技术

先考虑第一类 VMM. 操作系统自以为处在内核态(我们把这种状态称为虚拟内核态， virtual kernel mode)，并且访问特权指令时，会被 VMM 捕获，并且才和硬件做交互。如果在不支持虚拟化的操作系统上，那么会在宿主操作系统执行和模拟之前进行二进制改写，保证正确性。

虚拟化和半虚拟化的区别：半虚拟化时，要求对原操作系统进行改写，移除掉那些敏感操作，而是像虚拟化调用那样执行 hypervisor call. 我们把这时的 VMM 称作 Microkernel(微内核)。

### 内存虚拟化

显然，我们应该给每个客户操作系统准备一张页表，这被称为影子页表(shadow page table)。这一项工作是由 VMM 去完成的。为了减少开销，硬件上有一种名为嵌套页表(nested page table) 的支持。也就是直接能查到宿主机的物理地址，而无需 VMM 的参与。

### 云

云的五条特征：

- 按需自主服务。

- 普适的网络访问。

- 资源池，即资源分配对用户是透明的。

- 快速可伸缩。

- 服务可计量。

### x86 的虚拟化

- 
  

把虚拟化引入 x86 过程中的三个挑战：兼容性，性能和隔离。

x 86 的体系结构是不可虚拟化的！

在把 x86 虚拟化的过程中， VMM 中内含有决策算法，判断该操作应该采是直接执行，还是进行更多的二进制翻译等等。比如，当虚拟机处于内核态，或者可以关中断和执行I/O指令以及运行在实模式下时，必须采用二进制翻译。

VMware 由三部分组成： VMX，即用户态的程序；VMM驱动程序；包含复用 CPU 和内存等软件所需的 VMM.

实际上， VMware 和宿主操作系统是同权的！都是系统级别的程序。两个独立的系统级上下文的切换被称为系统切换(world switch).

ESX Server 是一种第一类虚拟化的解决方案。
