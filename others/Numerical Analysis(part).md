# 第零章 基础

## 1、多项式计算

暴力计算，复用幂结果，Horner方法

## 2、二进制数

十进制数到二进制数的转换。整数部分，是平凡的。小数部分也是类似的。考虑到分数不方便计算，所以有了乘2减1的trick。

## 3、实数的浮点表示

一个浮点数由符号、尾数和阶（指数）三部分组成。我们规定，浮点数的**正规化形式**是$\underline +1.bbb...b\times2^p$。一个浮点数以这种形式存储时，我们称其为**左恰当的**。

定义：$machine\ \epsilon$表示1和大于1的最小浮点数之间的差值，记作$\epsilon_{mach}$（这是用于刻画尾数的精度的！）

考虑到存储能力是有限的，第一种方法是对尾数截断。我们称这样的方式是截断法(chopping)。第二种方法是类似四舍五入的方法。考虑截断精度的后一位。如果是0，那么直接舍去。反之，则进位。特殊的，如果除截断的后一位外，之后的位数都为0，那么我们舍入的依据就是使最后一位恰好等于0。这样的目的是为了避免在等距的舍入时产生系统行的偏差。这称为舍入法(rounding)。

我们用$fl(x)$表示$x$的双精度浮点数。

在这种计算模型下，${|fl(x)-x|\over |x|}\leq {1\over 2} \epsilon_{mach}$

### 机器表示

以double为例：

$$
se_1...e_{11}b_1...b_{52}
$$

第一位是符号位。接下来的11位是一个整数。其值代表浮点数的阶加上$2^{10}-1=1023$，如此，可以记录数字的阶在-1022到1023之间。全0和全1，我们另做他用。1023称为双精度格式的阶偏移。后面的52位就是正规浮点数尾数的二进制编码。

特殊的，当尾数数码全为0或者NaN(Not a Number)，阶为2047表示正无穷。当阶为0时，代表非正规化的浮点数形式，即$0.b_1...b_{52}\times 2^{-1022}$，这样扩大了浮点数可以记录的范围。形如这样的数称为**次正规浮点数**。所以，双精度中，能表示的最小的数是$2^{-1074}$

浮点数在进行加法运算时，可以暂时性具有更高的精度。因为有寄存器。但是最终还是要舍入。

## 4、有效数字的损失

当数值很小的时候就会发生。我们常常可以通过乘以共轭式的方法来缓解这个问题。

# 第一章 解方程

## 1、对分法

### 根隔离法

首先，我们要确认的确有根。那么，我们需要把根给括住。即找到$f(r_1)<0,f(r_2)>0$，这样，我们就锁定了根的区间。但这需要函数是连续的。也就是说，我们确定一个初始区间，然后开始二分迭代。

对于解的精确性，我们定义如下。若误差小于$0.5\times 10^{-p}$，则称解精确到p位小数。

## 2、不动点迭代

### 不动点

定义：若$g(r)=r$，则$r$是$g$的一个不动点。

如果我们可以将方程化归为$g(x)=x$的形式，那么我们可以通过初始估计$x_0$，随后进行不动点迭代。即，$x_{i+1}=g(x_i)$

这个数列可能收敛，也有可能发散。若收敛，那么一定是不动点。

对于每一个方程，我们都可以转化为一个不动点问题。

不动点迭代的几何原理可以用蛛网图解释。

### 不动点迭代的线性收敛性

$$
\lim_{i\to \infin}{e_{i+1}\over e_i}=S
$$

$e_i$表示第$i$次的误差。若$S<1$，则这种不动点迭代满足速度为$S$的线性收敛。

若$g$连续可微，$g(r)=r,|g'(r)|<1$，那么当初步估计充分接近r时，不动点迭代以S线性收敛于$r$。

如果对于充分接近于$r$的初始估计而言，迭代方法收敛，那么称这个方法为局部收敛到r。

所以，当$|g'(r)|<1$时，不动点迭代法局部收敛。

不动点迭代需要一个停止准则。

## 3、精度的界限

假设$f$是一个函数，$r$是一个根。若$x_c$是$r$的近似值。称$x_c$的后向误差为$|f(x_c)|$，前向误差为$|r-x_c|$

若根$r$具有性质$0=f(r)=f'(r)=...=f^{m-1}(r),f^m(r)\not=0,f$在$r$处有$m$重根。若重数为1，则$r$是单根。

在重根附近，函数图线较**平坦**。在这附近，前向误差比后向误差要大得多。

### Wilkinson多项式

这是一个只有单根，但是数值上却很难确定的多项式。

$$
W(x)=(x-1)(x-2)...(x-20)
$$

若输入的小误差导致输出或解的大误差，那么我们称这个问题是**灵敏的**。

假设问题是求$f(x)=0$的根$r$，但是对系数输入作一个小的改变$\epsilon g(x)$，设$\Delta r$是相应根的改变，则

$$
f(r+\Delta r)+\epsilon g(r+\Delta r)=0
$$

将$f$和$g$展开成一次Taylor多项式

$$
f(r)+(\Delta r)f'(r)+\epsilon g(r)+\epsilon(\Delta r)g'(r)+O((\Delta r)^2)=0
$$

$\epsilon$是一个小量。那么，对上式进行近似化简，我们可以得到$\Delta r\approx -\epsilon{g(r)\over f'(r)}$

若$r$是$f(x)$的单根，$r+\Delta r$是$f(x)+\epsilon g(x)$的根，若$\epsilon<<f'(r)$，则$\Delta r\approx -{\epsilon g(r)\over f'(r)}$

我们定义，误差放大因子为$相对前向误差\over 相对后向误差$。

误差放大因子可以帮助我们预测在计算过程中，损失了多少精度。

条件数定义为$xf'(x)\over f(x)$。若条件数接近1，则称其为良态问题。若条件数大，那么称其为病态问题。

## 4、Newton法

这是一种收敛方法很快的解方程方法。

从初始估计$x_0$处出发，在$(x_0,f(x_0))$处作切线。切线可以得到与$x$轴的交点。这个交点给出了根的进一步近似值，记作$x_1,x_1=x_0-{f(x_0)\over f'(x_0)}$

如此进行迭代，有$x_{i+1}=x_i-{f(x_i)\over f'(x_i)}$

Newton法收敛的速度很快，是因为这种方法具有**二次收敛性**。

我们定义，$if\ M=\lim{i\to \infin}{e_{i+1}\over e_i^2}\not=\infin$，那么这种方法是二次收敛的。

假设$f$是**二次连续可微函数**，$f(r)=0,f'(r)\not= 0$,那么Newton法局部收敛于$r$且二次收敛于$r$。

Newton法可以看作是一种特殊的不动点法。由于在不动点处导数为0，所以局部收敛。

当$f'(r)=0$时，则Newton法不是二次收敛的。

对于$[a,b]$上$(m+1)$次连续可微函数$f$在$r$处有$m$重根，那么Newton法局部收敛到$r,\lim_{i\to\infin}{e_{i+1}\over e_i}={m-1\over m}$

如果我们事先知道根的重数，那么可以对Newton法作出修正：$x_{i+1}=x_i-{mf(x_i)\over f'(x_i)}$，此时，其又二次收敛了。

Newton法不一定一定可以收敛到一个根。但是，Newton法是局部收敛的，所以我们可以挑选一个合适的领域，使得Newton法收敛。

## 5、不用导数求根

在有些情况下，可能不能得到导数。此时，我们可以应用**割线法**。在每一个近似估计点$(x_i,f(x_i))$处，我们可以用${f(x_i)-f(x_{i-1})}\over x_i-x_{i-1}$来代替Newton法中的导数。这样，我们就得到了割线法。割线法对单根的收敛性是超线性（在线性收敛和二次收敛之间）的。因为当$i$足够大时，$e_{i+1}\approx ke_i^{1.62}$

有三种重要的对割线法的推广。

### 试位法

考虑类似对分法的方式。初始估计先落在根的两侧。随后根据割线法算出的结果，选择性地舍弃掉一个点，使得根依旧落在当前区间中。

Muller法和反二次插值法不作深入介绍。

### Brent方法

这是一种混合方法。通过依次尝试使用反二次插值法、割线法、对分法，保证不确定度经过一次计算可以减半。

# 第二章 方程组

## 1、高斯消去法

化为上三角形，然后回代。对于含有n个变量的n个方程的方程组，完成消元需要${n^3\over 3}+{n^2\over 2}-{5n\over 6}$次乘除法。完成回代需要${n^2\over 2}+{n\over 2}$次乘除法。

因此，高斯消元法是一种$O(n^3)$的算法。

## 2、LU分解

方程组可以写成$Ax=b$的形式。$b$称为右端项。

我们假定$A=LU$，$L$是下三角矩阵，$U$是上三角矩阵。

$$
Ax=b\leftrightarrow LUx=b\\
let\ Ux=c\\
Lc=b
$$

因为$L$和$U$都是三角矩阵，所以我们可以先解$c$，再解$x$。

这样做的好处在于，假设我们要做$k$次$Ax=b_i$这个运算，那么我们只需要分解一次$LU$，之后便可以复用分解出的结果，只需要进行回代的工作。这样，使得之后每次的解方程组复杂度下降到$O(n^2)$。

## 3、误差的来源

定义：n维向量的无穷大范数（最大范数）$||x||_\infin=\max|x_i|$

设$x_c$是线性方程组$Ax=b$的近似解，则残差$r=b-Ax_c$。后向误差是$||b-Ax_c||_\infin$，前向误差是$||x-x_c||_\infin$

remark：前向误差刻画了近似解和精确解之间的距离，后向误差刻画了近似解和精确解代入函数之后的差距。后向误差刻画的是解和线性方程之间的距离。前向误差刻画的是两个向量之间的距离。

同上。误差放大因子依旧是相对前向误差和相对后向误差之比。

我们定义，方阵$A$的条件数$cond(A)$是对所有的右端项求解$Ax=b$的最大可能误差放大因子。

remark：其衡量的，就是对于观测值的微小扰动$\delta A$,对于最终的数值解$x_c$的影响程度大小。

$A$的条件数$cond(A)=||A||\cdot||A^{-1}||$

$||A||$是矩阵的算子范数。

范数具有三条性质：值非负，范数等于0，必为0元素；数乘可以移动，具有齐性；符合范数不等式$||x+y||\leq||x||+||y||$

我们定义矩阵的算子范数：$||A||=\max{||Ax||\over ||x||},x\not=0$

remark：$||A^{-1}||=\max{||A^{-1}y||\over||y||}={1\over\min{||y||\over||A^{-1}y||}}={1\over min{||Ax||\over||x||}}$

高斯消元中的第二个误差来源是摆动。也就是说，在消元时，我们要尽量让乘上的倍数较小。否则的话，过大的乘数会导致信息的损失。

## 4、PA=LU分解

部分选主元的想法。也就是，在每一列消元之前，比较数的大小，确定第一列中最大元素所在的位置，将其交换到主元行。

设$P$是由单位矩阵作一系列特定行交换形成的置换矩阵。

## 5、迭代方法

### Jacobi方法

求解方程组的不动点迭代法(FPI)。

对于一个$n\times n$的矩阵$A$而言，倘若每行上，对角线上的元素的绝对值比该行其他所有元素的绝对值之和更大，那么这个矩阵是**严格对角占优**的。

如果一个矩阵是严格对角占优的，那么这个矩阵是非奇异的，并且$Ax=b$运用Jacobi方法可以收敛到唯一解。

$$
Ax=b\\
(D+L+U)x=b\\
Dx=b-(L+U)x\\
x=D^{-1}(b-(L+U)x)
$$

对于Jacobi方法而言，即$x_{k+1}=D^{-1}(b-(L+U)x_k)$

### Gauss-Seidel方法

校正在当前步数即发生。在当次计算中，若某个待求解量已经有当次估计，那么会用当次估计参加计算。即$x_{k+1}=D^{-1}(b-Ux_k-Lx_{k+1})$

### SOR(逐次超松弛)

给定一个实数$\omega$，新的估计值$x_{k+1}=(1-\omega)x_k+\omega x_{cal}$

$x_{cal}$为按照Jacobi方法算出的数据。

$\omega$被称为是松弛参数。当$\omega>1$时，被认为是超松弛的。

松弛方法通常运用于求解稀疏方程组。

### 6、共轭梯度法

如果$A$是正定的，为了求解$Ax=b$

$x_0=0,d_0=r_0=b$

当$r_i\not=0$时，重复如下操作：

$$
\alpha_i={r^T_{i-1}r_{i-1}\over d^T_{i-1}Ad_{i-1}}\\
x_i=x_{i-1}+\alpha_id_{i-1}\\
r_i=r_{i-1}-\alpha_iAd_{i-1}\\
\beta_i={r_i^Tr_i\over r_{i-1}^Tr_{i-1}}\\
d_i=r_i+\beta_id_{i-1}
$$

通过运算可以得到，$Ax_i+r_i=Ax_{i-1}+r_{i-1}=b$

故$r_i$是第$i$步的残差。

并且，每一步产生的$r_i$相互正交。

矩阵的乘法的复杂度是很高的。

当$A$是一个病态矩阵时，它会累积较大的误差。

## 7、非线性方程组系统

### 多变量Newton法

recap:$x_{k+1}=x_k-{f(x_k)\over f'(x_k)}$

类似于导数，我们可以定义Jacobi矩阵：

若

$$
f_1(u,v,w)=0\\
f_2(u,v,w)=0\\
f_3(u,v,w)=0\\
F(u,v,w)=(f_1,f_2,f_3)\\
DF(x)=\begin{bmatrix}
{\partial f_1\over \partial u}&
{\partial f_1\over \partial v}&
{\partial f_1\over \partial w}\\
{\partial f_2\over \partial u}&
{\partial f_2\over \partial v}&
{\partial f_2\over \partial w}\\
{\partial f_3\over \partial u}&
{\partial f_3\over \partial v}&
{\partial f_3\over \partial w}\\
\end{bmatrix}
$$

问题就转化为了，求$F(x)=0$，记其根为$r$

在$x_0$附近进行泰勒展开，得$F(x)=F(x_0)+DF(x_0)\cdot(x-x_0)+o(x)$

$0=F(r)\approx F(x_0)+DF(x_0)(r-x_0)$

$-(DF(x_0))^{-1}F(x_0)\approx r-x_0$

所以，我们有如此迭代：

$x_{k+1}=x_k-(DF(x_k))^{-1}F(x_k)$

$(DF(x_k))(DF(x_k))^{-1}F(x_k)=F(x_k)$

，我们只要计算这个方程的部分解，代入迭代式即可。不必求矩阵的逆。

### Broyden方法

这是在Jacobi矩阵不易求得时的方法。

假设$A_{i-1}$是在$i-1$步得到的Jacobi矩阵的最好近似，并且用于产生$x_i=x_{i-1}A^{-1}_{i-1}F(x_{i-1})$

进一步校正，我们希望$A_i\delta_i\approx\Delta_i,\delta_i=x_i-x_{i-1},\Delta_i=f(x_i)-f(x_{i-1})$

我们考虑$\delta_i$的正交补，$\delta_i\cdot w=0,A_iw=A_{i-1}w$

综合上式，我们得到$A_i=A_{i-1}+{(\Delta_i-A_{i-1}\delta_i)\delta_i^T\over \delta_i\cdot\delta_i}$

我们也可以使用Sherman-Morrison公式得到Broyden方法。$A_0$可以选择一个单位矩阵。Broyden方法对单根而言都是超线性收敛的。

# 第三章 插值

## 1、数据和插值函数

### Lagrange插值法

假设经过$(x_1,y_1),(x_2,y_2),(x_3,y_3)$

$P(x)=y_1{(x-x_2)(x-x_3)\over (x_1-x_2)(x_1-x_3)}+y_2{(x-x_1)(x-x_3)\over (x_2-x_1)(x_2-x_3)}+y_3{(x-x_1)(x-x_2)\over (x_3-x_1)(x_3-x_2)}$

就是关于这些点的Lagrange插值多项式。

多项式插值的主要定理：如果要对n个点插值，那么有且仅有一个次数小于等于n-1的多项式，满足对上述点插值。如果次数为$d\geq n$,则有无穷多种插值方案。（可以看做额外要求经过一个不同的点）

### Newton均差

$$
f[x_k]=f(x_k)\\
f[x_k\ x_{k+1}]={f[x_{k+1}]-f[x_k]\over{x_{k+1}-x_k}}\\
f[x_k\ x_{k+1}\ x_{k+2}]={f[x_{k+1}\ x_{k+2}]-f[x_k\ x_{k+1}]\over x_{k+2}-x_k}
$$

$$
P(x)=\sum_{i=1}^nf[x_1...x_i](x-x_1)...(x-x_{i-1})
$$

这种方法类似于Horner规则。简化了计算。

实际上，插值可以看做是一种有损压缩的方式。它用一些代表性的点来表征整个函数。

remark：点值表示法？

所以，我们可以选择一些点，来近似表示函数。

## 2、插值误差

### 插值误差公式

$$
f(x)-P(x)={(x-x_1)...(x-x_n)\over n!}f^{(n)}(c)\\
c\in[\min\{x_1,...,x_n\},\max\{x_1,...,x_n\}]
$$

### Runge现象

在数据区间较靠外的部分，有较大的误差。

### 3、Chebyshev插值

目标：使插值中的$(x-x_1)...(x-x_n)$的最大值尽可能小。

$$
(\max_{-1\leq x\leq1}|(x-x_1)...(x-x_n)|)\ is \ minimum,\\
iff\ x_i=\cos{(2i-1)\pi \over 2n},the\ value\ is\ {1\over 2^{n-1}}\\
i.e.(x-x_1)...(x-x_n)={1\over 2^{n-1}}T_n(x)
$$

选取Chebyshev多项式的根作为插值基点，使得误差在区间内均匀分布。

$$
T_n(x)=\cos(n\arccos x)
$$

对于$\forall n$而言，$T_n(x)$确实是一个多项式。

## 4、三次样条

运用多个不同的多项式公式，来拟合整个函数。

三次样条使用的是三次多项式。并且，要求不同函数之间连接点**光滑**，即函数值、一阶导、二阶导数都相同。

在两个样本点之间，使用的是同一个多项式。

在$[x_2,x_3]$这个区间内，用函数$S_2(x)=y_2+b_2(x-x_2)+c_2(x-x_2)^2+d_2(x-x_2)^3$

来拟合。

特殊的，如果在端点处的二阶导数均为0，那么称这样的样条为**自然三次样条**。对于一组数据点，存在唯一的自然三次样条来拟合它们。

针对不同的端点条件，比如规定二阶导数为特殊值，称为**曲率-调准三次样条**。规定一阶导数为特殊值，称为**夹子三次样条**。

## 5、Bézier曲线

控制节点处斜率的样条。但是不再保证**光滑性**。

每一段样条由四个点确定。两端的点为端点，中间两个点表征端点处切线方向，称为控制点。

# 第四章 最小二乘

## 1、最小二乘和正规方程

如果一个方程组是无解的，那么我们称这个方程组是**不相容**的。

$Ax=b$中，最接近的$x$称为最小二乘解。

$$
(b-A\bar x)\perp\{Ax|x\in R^n\}\\
(Ax)^T(b-A\bar x)=0\\
x^TA^T(b-A\bar x)=0\\
A^T(b-A\bar x)=0\\
A^TA\bar x=A^Tb
$$

上述中的最后一个方程称为正规方程。我们度量最小二乘解准确度的依据是**2-范数**，即残差的欧几里得长度（或者标准差）。

尽管最小二乘很不错，假定输入的数据中有误差，则$cond(A^TA)\approx cond(A)^2$

,这样会增大问题是病态的可能性。更复杂的方法可以不必用$A^TA$就可以计算二乘解。

## 2、模型综述

对于周期性数据，我们可以考虑引入正弦曲线和余弦曲线来拟合之。

对于指数型模型，我们可以通过取对数的方法，来把模型线性化。

即，$y=c_1e^{c_2t}$

$y=c_1t^{c_2}$也可以取对数，然后换元，成为线性模型。

## 3、QR分解

也就是说，把一个矩阵分解为一个标准正交阵，和一个上三角矩阵的乘积。$R$多余的行数值为0。

$$
||Ax-b||_2min\\
||QRx-b||_2min\\
||Rx-Q^Tb||_2min(标准正交阵乘法不改变2-范数)\\
通过适应x，let\ Q^Tb=d\\
d_1,...,d_n能被化为0\\
误差向量e，||e||_{2min}=\sum_{i=n+1}^md_i^2
$$

$$
\hat d=Q^Tb的前n分量，用\hat R\bar x=\hat d解得最小二乘解。
$$

这就是Gram-Schmidt法的QR分解。

### Householder反射

如果两个向量欧氏长度相同，那么$w-x\perp w+x$

我们考虑：是否存在一个矩阵，能够把$x$变换为$w$

首先，投影到$v=w-x$上的投影矩阵为$P={vv^T\over v^Tv}$

考虑直观图像，有$w=x-2Px$

令$H=I-2P,Hx=w$

## 4、非线性最小二乘

### Gauss-Newton方法

考虑n个未知数，m个方程所组成的方程组。

$$
r_1(x_1,...,x_n)=0\\
...\\
r_m(x_1,...,x_n)=0
$$

$$
E(x_1,...,x_n)={1\over2}\sum_{i=1}^mr_i^2={1\over 2}r^Tr
$$

我们令$F(x)=\nabla E(x)=\nabla({1\over 2}r(x)^Tr(x))=r(x)^TDr(x)$

$Dr(x)$是$r(x)$的Jacobi矩阵。

$$
DF(x)=D((Dr)^Tr)=(Dr)^T\cdot D^r+\sum_{i=1}^mr_iDc_i
$$

$$
c_i是Dr的第i列。D_{ci}=H_{ri}\\
H_{ri}=\begin{bmatrix}
\partial^2r_i\over\partial x_1\partial x_1&...&\partial^2 r_i\over\partial x_1\partial x_n\\
...&...&...\\
\partial^2 r_i\over \partial x_n\partial x_1&...&\partial^2 r_i\over\partial x_n\partial x_n
\end{bmatrix}
$$

如果省略后面这一项复杂的求和，那么问题可以得到大大简化。我们称这种方法为拟Newton法。

$$
for\ k=0,1,...\\
Dr(x_k)^TDr(x_k)v_k=-Dr(x_k)^Tr(x_k)\\
x_{k+1}=x_k+v_k
$$

# 第九章 随机数及其运用

## 1、随机数

最基本的一种生成随机数的类型：线性同余生成元。

$$
x_i=ax_{i-1}+b(mod\ m)\\
$$

定义：如果一个素数可以写成$2^p-1$的形式，那么我们称它为梅森素数。

最小标准随机数生成元中规定，$m=2^{31}-1,a=7^5=16807,b=0$

指数随机变量$V$通过概率分布函数$p(x)=ae^{-ax}$的方式来选取正数。

所以，其累积分布函数为$\int_0^xp(x)dx=1-e^{-ax}$

标准正态分布的随机变量也是通过类似的概率分布函数，$p(x)={1 \over\sqrt{2\pi}}e^{-{x^2\over2}}$

来选取的。

## 2、蒙特卡罗模拟

蒙特卡罗问题的误差正比于$n^{-{1\over 2}}$

为了加快蒙特卡罗模拟的收敛速度，我们可以使用**拟随机数**而非伪随机数。拟随机数不像伪随机数那样具有独立性，但是，拟随机数可以**自避免**，这样可以避免生成的随机数团聚在一起。为了生成拟随机数，我们可以使用一种称为**基p的低歧义数列**。

# 第十章 三角插值和快速傅里叶变换

## 1、傅里叶变换

采用复数，是为了简化三角函数的记法。

**Euler公式**：$e^{i\theta}=\cos\theta+i\sin\theta$

所以，$z=a+bi=re^{i\theta}$

Euler公式可以简化角度加减的记法。

我们可以定义出原根的概念。如果$z^n=1$，我们称$z$为$n$次单位根。

如果一个$n$次单位根，$\forall k<n$，其不是$k$次单位根，那么我们称这个$n$次单位根是原根。

令$\omega=e^{-2\pi i/n}$，则$\sum_{j=0}^{n-1}\omega^j=0$

这是因为$(1-\omega)(\sum_{j=0}^{n-1}\omega^j)=(1-\omega^n)=0$

我们因此可以得到原根的性质$\sum_{j=0}^{n-1}\omega^{jk}=n,n|k$否则，其值为$0$。

我们需要定义离散傅里叶变换的概念。设$x=[x_0,...,x_{n-1}]^T,x_i\in R$

$x$的离散傅里叶变换是$y=[y_0,...,y_{n-1}]^T$其中$y_k={1\over \sqrt n}\sum_{j=0}^{n-1}x_j\omega^{jk}$

因此，我们可以定义出傅里叶矩阵。

$$
F_n={1\over \sqrt n}\begin{bmatrix}
\omega^0&\omega^0&\omega^0&...&\omega^0\\
\omega^0&\omega^1&\omega^2&...&\omega^{n-1}\\
&&...\\
&&...\\
\omega^0&\omega^{n-1}&\omega^{2(n-1)}&...&\omega^{(n-1)^2}
\end{bmatrix}
$$

注意到，$F_n$是个对称阵。并且，除去第一行以外，每一行的元素和为0。

傅里叶矩阵有一个显式的逆矩阵。那就是：

$$
F_n^{-1}={1\over \sqrt n}\begin{bmatrix}
\omega^0&\omega^0&\omega^0&...&\omega^0\\
\omega^0&\omega^{-1}&\omega^{-2}&...&\omega^{-(n-1)}\\
&&...\\
&&...\\
\omega^0&\omega^{-(n-1)}&\omega^{-2(n-1)}&...&\omega^{-(n-1)^2}
\end{bmatrix}
$$

所以，$x=F^{-1}_ny$

注意到，$e^{-i\theta}=\bar{e^{i\theta}}$

所以，$F_n^{-1}=\bar F_n$

因此，傅里叶矩阵是一个酉矩阵。酉矩阵和实系数下的正交阵相同，有$||Fv||^2=||v||^2$

设$\{y_k\}$是$\{x_j\}$的DFT，$x_j\in R$,那么，我们一定有$y_0\in R,y_{n-k}=\bar y_k$

所以，这里具有一定的对称性，可以用于简化计算。

但是，DFT的复杂度太高了。FFT解决了这一个问题。

FFT的思想，是把偶数阶的项全部放在前面。再利用单位根的性质，把每一项中化出相同的式子，从而简化运算。
