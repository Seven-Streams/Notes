# CAQA

## 量化设计与分析基础

RISC(Reduced Instruction Set Computer，精简指令集计算机)体系结构，关注在指令级并行的利用，以及如何更好地利用缓存两个问题上。

由于硬件性能地提高，很多编程以生产效率更高的语言(java)等进行，而不是效率更高的C类进行。但是，为了保持生产效率，并且尝试缩小性能的差距，即时编译器和跟踪编译的解释器取代了传统的编译器和链接器。此外，在互联网上课以使用的“软件即服务(SaaS)”也取代了必须要在本地进行安装和运行的紧缩套装软件。

Dennard sacling(登纳德缩放比例定律)在2004年左右终结。它描述的是对于给定的硅面积，增加晶体管的数量，功率密度恒定。这是因为晶体管尺寸下降，速度更快，耗电量下降。其终结的原因在于无法在保持集成电路的可靠性的情况下，进一步地减小电流和降低电压。

一位其终结，半导体行业开始采用多处理器或者多核设计。这意味着除了指令级并行(ILP)外，数据级并行(DLP)和线程级并行(TLP)都开始成为人们关注的对象。

近期终结的Moore's Law(摩尔定律)。即1-2年内，芯片上可容纳的晶体管数量翻倍。

处理器性能提升速度放缓的四个原因：

- 摩尔定律的放缓和登纳德缩放比例定律的终结。

- 微处理器的功耗预算需要保持不变。

- 多核高效处理取代了单个大功耗的处理器。

- 多重处理已经达到Amdahl定律的上限。

### 计算机的分类

- 个人移动设备(手机、平板等)

- 桌面计算机

- 服务器(关注于可用性、可扩展性。高吞吐率)

- 集群/仓库级计算机(可用性。性价比、功耗)

- 物联网/嵌入式(比如智能手表、智能音箱)

### 并行结构的分类

#### 应用程序

- 数据级并行(DLP)：许多数据项可以同时操作。

- 任务级并行(TLP)：创建的工作任务可以单独执行并且主要采用并行方式执行。

#### 硬件的利用方式

- 指令级并行

- 向量体系结构、GPU、多媒体指令集等。利用数据级并行。

- 线程级并行。

- 请求级并行。

### 计算机体系结构的定义

指令集体系结构(ISA)：相当于软件和硬件之间的界限。

#### ISA的分类

- 寄存器-存储器ISA.可以通过多种指令访问存储器。

- 载入-存储ISA.它们只能用载入或者存储指令来访问寄存器。

#### 寻址

有些体系结构要求读取对象必须是对齐的。但像RISCV中之类的就不要求。一般而言，对齐的对象访问起来会快一些。

在RISCV中，有三种寻址的模式。分别是寄存器寻址，立即数寻址，和位移量寻址。

#### 操作数和指令

操作数大小都支持比如8位、16位、32位等等。常见的操作指令有数据传输指令、算术逻辑指令、控制指令和浮点指令。

#### ISA的编码

就两种不同的选择：到底是固定长度还是可变长度？

在CAQA中，体系结构指的是这三方面：ISA、组成或微体系结构、硬件。

### 技术趋势

- 集成电路逻辑技术。晶体管上数量一直在增加，但是速度放缓了。

- 半导体DRAM。DRAM的增速也下降了。之前是3年增加到原来的3倍，但现在已经达不到了。

- 半导体闪存。目前，闪存增大速率还是很快的。大约每年增加50%到60%，大概是两年翻倍的样子。

- 磁盘技术。目前，磁盘技术基本密度饱和了。最后的希望是通过HAMR(热辅磁记录)的方式来增大其密度。也就是进一步优化磁盘读写头。

- 网络技术。网络性能目前取决于交换机的性能和传输系统的性能。

### 性能趋势

带宽，或者说是吞吐量指的是在给定时间内完成的总工作量。

延迟，或者说是响应时间，指的是一个事件从开始到完成所需要的时间。比如一次磁盘访问需要的毫秒数等等。

带宽的改进速度超过延迟。根据经验，带宽的增加速度至少是延迟改进速度的平方。

集成电路的制造工艺一般用**特征尺寸**(feature size)来衡量。其指的是晶体管或者一根连线在x轴方向或者y轴方向上的最小尺寸。我们常说的7nm指的就是这个。

### 集成电路的功耗和能耗趋势

#### 最大功耗

最大功耗对电源系统提出了要求。如果它的最大功耗超过了电源所能提供的范围，那么电压一般会发生下降，从而导致器件无法正常工作。现代处理器中，如果其发现电压供应上的问题，那么它就会减缓速度来调整电压，尽管这样会导致性能上的降低。

#### 持续功耗

衡量它的指标一般被称为热设计功耗(TDP)，它在对系统的散热提出的要求。冷却系统的散热，一般而言绝对不能小于TDP。但由于最大功耗一般会超过TDP,当现代处理器发现温度接近结点温度的上限是，会降低时钟频率来减小功耗。如果其不奏效，可能会启用热过载保护装置使芯片断电。

#### 能耗

功耗，指的是单位时间的能耗。但是，一般而言，用能耗去衡量处理器更加好一些。因为能耗和特定的任务，以及完成该项任务所需要的时间相互关联。也就是说，能耗等于平均功耗乘上时间。

能耗用于衡量处理器是合理的，而功耗一般用来确定指标，比如散热量等等。

#### 微处理器的内部

对于CMOS芯片而言，主要的能耗源就是开关晶体管，也被称为动态能耗。每个晶体管的能耗，和由该晶体管驱动的容性负载和电压平方的乘积成正比。如果我们要考虑动态功耗，那么动态功耗应该正比于容性负载、电压平方和开关频率的乘积。

因此，对于固定的一项任务而言，降低时钟频率可以降低功耗，但是不会降低能耗。

目前，有几种方式尝试在时钟频率和电源电压保持不变的情况下来提高能效。

- 以逸待劳。关闭非活动模块的时钟。比如没有浮点数操作时的浮点单元。

- 动态电压-频率调整。通过降低电压，减少频率，使其在空闲时间功耗小一些。

- 针对典型情景进行设计。比如低功耗模式，在空闲情况下对磁盘采用低转速模式等等。

- 超频。在少数几个核上用较高的频率短时运行，直到温度开始上升。

尽管动态功耗更为主要，静态功耗也是确实存在的。静态功耗与静态电流和电压的乘积成正比。也就是说，静态功耗与器件数目成正比。

如果增加晶体管的数目，那么它们就算空闲着，也会增加功效。功耗极低的系统可能会关闭非活动模块的电源(电源门控)来缓解这个问题。

如果能选用速度快，能耗低的处理器，使其他部分进入睡眠，也有助于降低整体能耗。这种策略被称为**竞相暂停(race-to-halt)**。

“暗硅”：由于热限制，在任意时刻，一个芯片的大部分都不能使用。使用领域专用的一些处理器，可以想办法减少那些低能效的运算，从而提高能效。也就是说，把通用核和专用核结合使用。

### 成本趋势

学习曲线：芯片的制造成本随着时间的推移而降低。学习曲线是根据**良率**测得的。良率，指的是成功通过测试的器件占所占生产器件总数的百分比。

$$
集成电路的成本=\frac{晶片成本+晶片测试成本+封装与最终测试成本}{最终测试良率}\\

$$

关于其中的晶片成本，我们有：

$$
晶片成本=\frac{晶元成本}{每个晶圆上的晶片数\times 晶片良率}
$$

每个晶圆上的晶片数，我们可以通过下式计算：

$$
每个晶圆上的晶片数=\frac{\pi\times(晶圆直径/2)^2}{晶片面积}-\frac{\pi\times晶圆直径}{\sqrt{2\times晶片面积}}
$$

前一项是朴素的计算。后一项是对边角料的处理。

### 可信任度

这一点在计组中有所提及。指标有**MTTF**(平均无故障时间)，**FIT**(故障率)，**MTTR**(平均修复时间)，**MTBF**(平均故障间隔时间)=MTTF+MTTR。

我们定义，模块可用性为$\frac{MTTF}{MTTF+MTTR}$

### 性能的测量、报告和汇总

对于用户而言，一般更加在意缩短响应时间；WSC的操作人员就更关心吞吐量。

最直接的执行时间被定义为响应时间(elapsed time)，即完成一项任务的延时。CPU时间则指的是处理器执行计算的时间，不包括等待IO等时间。

### 计算机设计的量化原理

- 充分利用并行。

- 局部性原理。

- 重点关注常见情形。

- Amdahl定律。

### 处理器性能公式

$CPU时间=程序的CPU时钟周期数\times 时钟周期时间$

我们定义CPI(每时钟周期指令数)为：$\frac{程序的CPU时钟周期数}{指令数}$

从而，CPU时间也可以表示为$指令数\times CPI\times 时钟周期时间$

## 存储器层次结构设计

个人移动设备：寄存器、L1cache、L2cache，经过存储总线到达内存，然后之后是存储。

对于电脑，一般会多一个L3缓存。存储一般由闪存和磁盘实现。

一般情况下，低层级存储器中的数据是上一级存储器中数据的超集。

如今由于多核处理器，对内存带宽的需求很大。为了实现高带宽，目前有多种方式：

- 缓存的多端口和流水线。

- 利用三级缓存。每个核有两级私有缓存，一个共享的L3缓存。

缓存缺失率的原因(3C)：

- 强制(compulsory)缺失

- 容量(capacity)缺失

- 冲突(conflict)缺失

基本的降低缺失率的方法：

- 增大缓存块。

- 增大缓存总容量。

- 提高相联度。

- 采用多级缓存。

- 为读缺失分配比写操作更高的优先级。因为读缺失，可能命中到写缓冲区正在写入最新值的位置。

- 在索引缓存期间避免虚实地址的转换，缩短命中时间。
  
  ### 存储器技术与优化

#### SRAM

SRAM不需要进行刷新。SRAM通常使用6个晶体管来保存1位数据，防止在读取时对信息造成的干扰。SRAM通常充当着cache作用载体的角色。目前，其基本被集成在芯片上。

#### DRAM

DRAM需要进行刷新，亦即"D"一词表征的含义。DRAM仅适用一个晶体管，来存储一位数据。为了实现地址线的复用，DRAM会在两个时期各发送地址的一半。在**行选通**(row access strobe, RAS)阶段发送一半地址，**列选通**(column access strobe, CAS)阶段发送另一半。这个名字的由来是DRAM的内部结构决定的。

#### SDRAM

同步DRAM(synchronous DRAM, SDRAM)，允许一种“突发式传输模式”。当处于这种模式后，无需再次指定新的列地址，数据就会被连续地发送。

SDRAM引入了**体**(bank，存储体)的概念。对于不同存储体的访问，是可以互相重叠的。每一个存储体都有各自的行缓冲区。当下一个访问对象的行和存储体与之前相同时，那么只需要发送列地址就可以进行访问了。

内存访问的过程是：

- DRAM控制器发送一个存储体编号和一个行号。该命令会打开这一行，并且把整行数据读入一个缓冲区中。

- 发送一个列地址。SDRAM根据所处的模式（单个请求还是突发请求）进行数据传输。

如果要对一个新行进行访问，那么存储体就需要进行充电。

双倍数据速率(double data rate, DDR)使得存储器在时钟周期上升沿和下降沿都可以传输数据。

目前，DRAM通常在双列直插存储模块(DIMM)这种小型电路板上进行销售。

#### 图形数据RAM(GDRAM)

为满足GPU需求进行特制。

- 接口更宽，有32位。

- 数据管脚上的最大时钟频率更高。

GDDR中的每个DRAM带宽是DDR3 DRAM的2-5倍。

#### 堆叠式或嵌入式DRAM

把DRAM通过堆叠、相依的方式嵌入到同一个处理器封装内部，降低访问延迟，带宽更高。其也被称为高带宽存储器(high bandwidth memory, HBM)。

#### 闪存

闪存和DRAM的体系结构区别很大，性质也很不同。

- 对闪存的读取时顺序进行的，并且一次会读取一整页。

- 重写闪存之前，必须把**整个块**进行擦除再写入。

- 闪存是非易失性的。

- 闪存限制了给每个块的写入次数。并且通过写入均衡技术来延长闪存寿命。

- 高密度的NAND闪存比SDRAM便宜，但是比磁盘贵。

#### 相变存储器技术

利用发热元件，使块状基底的状态在晶态和非晶态之间转换。二者的电阻特性不同，每个bit和基底上的一个二维网络有关。每一个比特都和一个交叉点对应。因此，它也被称为忆阻器(memristor).

### 存储器系统的可靠性

#### 硬错误

硬错误，也可以称作永久性故障。就是硬件完全废了，要用备用行来代替它的功能。

#### 软错误

软错误，或者说是瞬态故障。电路没有发生改变，但是存储单元中的内容却自顾自改变掉了。软错误一般可以通过纠错码来检测和纠正。但是对于仓储级服务器而言，要是用Chipkill来进一步降低不可恢复错误的数量。

### 优化缓存性能的高级方法

#### 小而简单的L1 cache

L1 cache的使命就是要足够快。因此，采用小而简单的cache可以缩短命中时间，并且降低功耗。

随着相联度增加，对该cache的访问时间和能耗都会增加。但是在近期，L1 chche选择的相联度还是稍高一些的。只是因为一般而言，访问缓存时至少需要两个时钟周期。因此，命中时间稍微长一点关系不会很大。

#### 路预测

缓存中另外保存了一些位，用来预测下一次缓存访问中的路，也就是组中的哪一块。

#### 缓存访问流水化及采用多体缓存

通过这种方式，可以实现在每个时钟周期内进行多次访问，从而提高缓存的带宽。每一个存储体中，会交错着进行存储。比如一个存储体中，可能存放有0,4,8,12...为tag的块。从而达到顺序交错的结果。

#### 非阻塞缓存

允许数据缓存在一次缺失期间继续提供缓存命中。也就是说，发生缓存缺失时，它会尝试命中别的需要的数据，比如i-cache中的信息，从而减少了停顿带来的损失。

但是，在实现上，非阻塞缓存是有一定困难的。主要有两个问题：

- 命中和缺失之间可能存在冲突。

- 跟踪尚未解决的缺失。

为了解决第一个问题，主要的方法是：为命中赋予比缺失更高的优先级，并且对相互冲突的缺失进行排队。

第二个问题，主要针对的是缺失返回的顺序不一定一致。因此，一般会引入一组被称为缺失状态处理寄存器(MSHR)的寄存器。每一个寄存器中都记录了每一个缺失应当进入缓存中的哪个位置，以及缺失的标签位的取值，以及关于哪个载入或存储指令导致了这一缺失的产生等等。

#### 关键字先行和提前重新执行

##### 关键字先行

在缓存缺失时，首先向存储器请求需要的字，当其到达缓存后立即发给处理器。然后慢慢载入剩余的数据。

##### 提前重新执行

向存储器请求缺失字时，依旧按照正常顺序执行。但是，只要块中需要的字到达缓存后，就立刻把它发送给处理器。

#### 合并写缓冲区

对于数据进行写操作时，我们可以把所有的写操作存放在一个写缓冲区中。在这里的写操作，处理器都会认为已经执行了。并且，如果发现较近的几个写操作，目标的地址是较为相近的，那么我们可以把这些地址放到同一个写条目下。也就是说，认为一个写操作是由多个相邻的写操作构成的一个向量写操作。这样的话，可以在一定程度上减少缺失惩罚。这种技术，我们称之为写合并(write merging)。

#### 编译器优化

- 循环交换。

- 采用分块的方式。即对于一个多层循环而言，可能采取将数组分为多个子矩阵的方式。它的好处在于，可以保证相邻的几次计算，只要不是强制缺失，相邻的数据都可以被放在缓存里。不然的话，可能会因为某一层循环需要的数据过大，把之前的放入缓存的一些仍旧需要的数据给移出去了。

#### 指令和数据的硬件预取

对于指令，如果发生了缺失，处理器一般一次性提取了两个块。

#### 编译器控制预取

两种预取方式：寄存器预取，和缓存预取。这些指令是由编译器插入的。

需要注意的是，这些指令可能会产生异常。如果异常发生，则认为执行了一次空指令即可。

#### HBM作为额外的一级缓存

HBM,即高带宽内存(High Bandwidth Memory)

对于缓存而言，一直有一个碎片化的问题(虚拟存储系统中也存在)。如果一个缓存块中，大部分数据都没有被用到，那么传输这样的数据块的时间其实是很浪费的。并且，如果一个数据块的大小过大，那么缓存中可以保存的数据块数目就会少很多，从而可能会导致更多的缓存缺失的发生。

为了解决前一个问题，一个有效的方案是增加更多的子块。(这和削减块大小区别很大吗？但是可以想到的是，一个动机是为了减少存放缓存标签的数量。)

### 虚拟存储器和虚拟机

进程的切换(process switch)，或者说是上下文切换(context switch)，决定了要想要使得程序可以更好地隔离开来，体系结构必须提供至少两种模式，即用户进程和操作系统进程。后者也可以被称为(kernel)进程或者管理(supervisor)进程。

变换旁路缓冲区(TLB)，其中的条目类似于缓存条目。其标签，保存的是虚拟地址的一部分。数据部分，保存的是物理页地址，保护字段，有效位，使用位和脏位(dirty bit)等等。

#### 虚拟机(VM)提供保护

为虚拟机提供支持的软件称为虚拟机监视器(VMM)或者管理程序(hypervisor)。虚拟机的底层硬件平台被称为宿主机(host)。

VM可以提供保护，也提供了一种可以运行整个软件栈的抽象，并且使得应用程序可以在不同的环境下运行，但是却共享着同一个硬件。

#### VMM的任务

- 保证客户软件在VM上的运行情况应该和原始硬件没有什么差别。

- 客户软件**不能**去更改实际系统资源的分配。

为了实现虚拟存储器的虚拟化，VMM区分了实际存储器(real memory)和物理存储器(physical memory)之间的概念。实际存储器可以视为是虚拟存储器和物理存储器之间的一个中间层级。还有一种说法，将二者分别命名为物理存储器和机器存储器。

VMM通过维护一张影子页表(shadow page table)来维护从客户虚拟地址空间到硬件物理地址空间的映射。用户不应当尝试去修改自己的页表。只有系统级进程对页表的修改操作可以被放行。

虚拟缓存并不是所有的体系结构里都有的。因为它存在着一些问题。

- 在切换进程时，虚拟地址会指向不同的物理地址。因此，切换进程后必须对缓存进行刷新。一种方案是通过进程识别符标记(PID)来作为缓存地址标记的一部分即可。

- 必须要提供保护。不然就不能够起到虚拟机的隔离作用。

- 虚拟缓存没有变得更普及的另一个原因，是因为OS和用户程序可能会为同一个物理地址分配了两个不同的虚拟地址。这些重复地址被称为同义地址，或者别名地址。如果虚拟缓存中有一个被修改了，而另外一个却没有同步更新，那就会出错。为了解决这个问题，需要做别名(alias)消去，也就是保证每个缓存块都拥有不同的物理地址。当然，软件也可可以通过强制的手段，共享某些地址位，也就是进行所谓的页面着色，来解决这个问题。也就是说，所有的别名地址都具有着相同的特征等等。

## 线程级并行

- 多处理器模型一：运行一组紧密耦合的线程协同完成一项任务：并行处理。

- 多处理器模型二：分别执行多个相对独立的进程，即请求级冰鞋。称为多道程序。

在多处理器中，分配给一个线程的计算量称为粒度大小。

多处理器我们根据存储器的组织方式分为两类：

- 对称共享存储器多处理器(SMP)，也称为集中式共享存储器多处理器。这也是大多数多核处理器采用的方式。其有时也被称为一致存储器访问(UMA)多处理器。每个处理器独自占有L1、L2等部分。共享层次更后的缓存。

- 分布式共享存储器(DSM)。每一个处理器都有自己独占的存储器。每个处理器可以向自己的存储器发出请求，也可以向远程的存储器发出请求。但显然，自己的存储器会更快一些。

在上述行文中的共享存储器，指的是地址空间(address space)是共享的。

### 多处理器缓存一致性

一致性(coherence)：定义读操作返回什么值。

连贯性(consistency,我觉得更应该被翻译成保序性)：定义写入值什么时候能被返回。

存储器系统一致性的条件：

- 同一个处理器，对某一个位置进行的读操作，跟在对该位置的写操作之后。倘若在这段时间里没有其他处理器对该位置进行写操作，那么一定会返回上一次写操作的值。

- 不同处理器，经过足够长的时间后，对某一个位置进行的读操作，跟在对该位置的写操作之后。倘若在这段时间里没有其他处理器对该位置进行写操作，那么一定会返回上一次写操作的值。

- 不同处理器，对某一位置的写操作是串行化的。

#### 一致性的基本实现方案

- 迁移

- 复制

主要问题在于，独占缓存部分的一致性是需要想办法保证的。

两种缓存一致性协议：

- 目录协议：把特定物理内存块的共享状态保存在一个位置中。称之为目录。

- 监听协议：监听协议有两种实现方式，写无效协议和写入更新(写入广播协议)。目前主流的视线方式是写无效协议。

在写穿透(write through)中，实现写无效协议是相对简单的。但是对于写返回(write return)中，想要实现写无效协议是更具有一定难度的。因为当前数据并非一定在存储器中。一种常见的解决方案，是每个处理器都要保持对读写信号的监听。如果发现自己拥有所请求内容的有效脏副本，那么就提供出去。为了跟踪缓存块是否被共享，可以再次添加一个bit。当被共享时，就需要对这个bit修改状态。并且在之后，也要把它放到总线上。这样的话，其他块就会收到相应的失效信息，并且这个块被标记成了**独占(exclusive)** 状态，并且拥有这个唯一副本的核被称为这个缓存块的拥有者。

#### 基本一致性协议的扩展

常见的一致性协议具有MSI三种状态(modified, shared, invalid)。MESI协议中添加了exclusive这种状态。MOESI则在MESI协议中添加了owned这种状态。表示该缓存拥有这个块的最新副本，但是在存储器中已经过时。

多处理器可能会产生的更多种缺失可能：真共享缺失和假共享缺失，前者顾名思义，而后者则是因为采用了基于无效的一致性算法导致的。

#### DSM和目录式一致性

目录协议中，保存了每个可缓存块的状态。比如有哪些缓存持有该块的副本，是否需要进行更新等等。

在目录协议的简单协议下，状态可能为：

- 共享。一个及以上节点缓存了这个块。存储器的值是最新的。

- 未缓存。没有节点缓存了这个块。

- 已修改。只有一个节点拥有这个缓存块的副本。并且，这个节点已经对这个块进行了写操作。

每个目录，都负责着本节点的存储器上，所有可缓存块的信息。

由于分布性的特点，处理器访问的地址不同，那么访存的时间也可能不同：因为分布式的特点，存储器可能在本节点，也可能不在。

#### 同步

在监听协议和目录协议中，我们默认了操作的原子性，但实际上并不好说。我们需要更多的操作来维护其原子性。

#### consistency

顺序一致性：每次程序执行的结果都是一样的。一种方式，是要求处理器把访存导致的所有无效信号都发射完毕，才可以宣告该处理器的访存操作完成。或者，推迟下一次访存，直到本次访存完全结束。也就是说，单个进程内的操作顺序必须和编码时的情况相同。

## 向量、 SIMD 和 GPU

### 向量体系结构

在 RV64V中，有这些组件：

- 向量寄存器：每个向量寄存器都保存一个向量，比如32个64位元素。

- 向量功能单元：用于计算。

- 向量载入、存储单元：从存储器中载入向量，或者把向量存储到存储器中。

- 标量寄存器：就是正常的那些寄存器。

动态寄存器类型设定：每一个向量寄存器需要配置它们的数据类型和宽度。

编译器可以为非跨迭代相关的代码生成向量指令，从而提高效率。

现代的向量计算机具有多条并行的流水线。它们可以在每个时钟周期生成一个或多个结果。护航指令组(convoy)：一组可以一起执行的向量指令。它们之间不包含任何结构冒险。

执行一个护航指令组所需的时间单位称为钟鸣(chime)。如果向量长度为$n$，那么执行这条指令所需的时间大概就是钟鸣乘上向量长度。

钟鸣的问题在于，它忽略了向量的启动延迟等问题。向量功能单元的流水线在被填满之前会有延迟。

谓词寄存器：如果迭代过程中有分支跳转语句，那么我们需要额外的一些操作。比如说，我们可以额外引入一个谓词寄存器，每一位用来代表是否要执行分支跳转。这一方式被称为向量掩码控制。

解决向量长度不确定的问题：额外添加一个向量长度寄存器来控制所有向量运算的长度。为了避免生成向量长度大于硬件可接受的长度，我们采用一种称为条带挖掘的技术，从而把过长的向量拆开来。

处理多维数组时，可能会有步幅的问题。也就是说，正在被相邻处理的元素不一定是物理上相邻的。向量按步幅加载时，效率可能会低一些。

集中-分散：支持稀疏向量的压缩表示。

### 多媒体 SIMD

和向量体系结构相比，它的问题在于没有向量长度寄存器，没有步幅或者集中/分散数据传送指令，也没有掩码寄存器。它的好处在于易于实现，并且不需要像向量体系结构中那样，有很高的传输带宽。

屋檐性能模型：把浮点性能、存储器性能、运算密度汇总在一个二维图形里。运算密度是梅子姐存储器访问的数据可以支持的浮点运算次数。

### 图形处理器

CUDA: Compute Unified Device Architecture

CUDA线程被认为是所有这些并行形式的统一主题。CUDA线程被分块、分组执行，称之为线程块(thread block)。

网格(grid) 指的是在 GPU上运行的，由一组线程块(thread block)构成的代码。

线程块调度器(thread block scheduler)把线程块指定给相对应的处理器。称之为多线程 SIMD 处理器。

专用存储器(private memory)：多线程 SIMD处理器中的每一条 SIMD 通道会获得片外 DRAM 上的一个专用部分。用来存储一些私有变量。而片上的存储器称为局部存储器。
