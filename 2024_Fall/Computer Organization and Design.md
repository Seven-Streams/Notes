# 计算机组成与设计

## 第一章 计算机抽象及相关技术

存储容量的十进制术语和二进制术语的区别：KB, MB, GB 为十进制；KiB, MiB, GiB 为二进制。

计算机体系结构的七个“伟大思想”：

- 使用抽象(abstraction)简化设计

- 加速大概率事件

- 并行提高性能

- 流水线提高性能

- 预测提高性能

- 存储分层

- 冗余提高可靠性

计算机的经典部件：输入设备，输出设备，存储器，数据通路（运算器），控制器。后二部分合称处理器。

RAM名字的由来：访问RAM中各部分的数据，时间基本一致。内存即为DRAM，D表示dynamic；cache则为SRAM,即static.

存储器分为易失性存储器和非易失性存储器。前者称为主存储器或一级存储器。后者称为二级存储器。

Amdahl定律：$t = \frac{a}{k} + a'$，a为被加速部分，k为加速比，$a'$为未加速部分。说明性能优化与整体的关系。

摩尔定律：18个月到24个月，集成电路上的晶体管数量翻倍，价格下降为原来的一半。目前，摩尔定律放缓。

SRAM,DRAM,二级存储器构成了存储器层次(hierarchy of memory)中的三层。

在个人移动设备中，二级存储器常是闪存而非磁盘。

闪存体积小，可靠性好，能耗低，但是一个单元写入1e5至1e6次就可能损坏。

CPI：CPU时间周期数除以指令数。(cycle per instruction)

## 第二章 指令

指令系统(instruction set):指令的词汇表。

JAVA一开始是解释器。如今为了性能，会进行即时编译从而运行。

指令的设计原则1：简单源于规整。要好翻译。

算术运算指令

在RISC-V中，32位称为字，64位称为双字(doubleword)。

指令的设计原则2：更少则更快。指令的操作数如果过多，那么很有可能会增加时钟周期。因为电信号传播耗时增加了。

数据传输指令

计算机分为大端编址和小端编址。大端编址：存储内容的高位存储在高字节中。小端编址则相反。

寄存器比内存显然快得多。并且，内存数据必须先读出。因此寄存器明显有着更高的吞吐率。

立即数操作也可以减少存取指令。RSIC-V有着常零寄存器，方便我们进行操作。

二进制补码(two's complement)

这种存储方式利用的是算术上的溢出。考虑到这一点，我们可以将有符号数用统一的公式表示。即：

$$
x=(x_{31}\times (-2)^{31})+\sum_{i=0}^{30}(x_i\times 2^i)
$$

符号扩展的过程就是在数据左侧填充符号位，正确地表达目标数。有符号载入也是这个过程。

为什么不使用反码？因为计算过程中需要额外的一步去计算。虽然正数和负数是平衡的，但却存在正零和负零。

计算机中的指令表示：二进制机器码。称这种指令的设计为指令格式。在RSIC-V中，指令都为32位长。符合简单源于规整的原则。我们把RISCV指令的每一部分称为一个字段。

一般的RISCV指令组成是：funct(7)+rs2(5)+rs1(5)+funct(3)+rd(5)+opcode(7)

所加的每一项都是指令的一个字段。

设计原则3：优秀的设计需要适当的折中。

上所述为R型指令。考虑到某些指令需要更长的字段，从而有:

- I型：immediate(12)+rs1(5)+funct(3)+rd(5)+opcode(7)

- S型：immediate(11:5)+rs2(5)+rs1(5)+funct(3)+immediate(4:0)+opcode(7)

为什么S型这么奇怪？这是为了保证rs1和rs2在不同指令中处于相同位置，降低硬件设计的复杂性。其他字段亦是同理。

考虑到指令长度与寄存器数量有不可分割的关系，所以大部分架构寄存器数量为16或32个。

逻辑操作

在RSICV中没有取反操作。因为取反等价于和-1取异或。

c++中位字段的使用：

```cpp
//ref:https://blog.csdn.net/wendyWJGU/article/details/134880176

#include <iostream>
using namespace std;

#include <fstream>
struct Data1
{
    unsigned int bit0 : 1;
    unsigned int bit1 : 3;
    unsigned int bit2 : 6;
    unsigned int bit3 : 22;
};

int main()
{  
    unsigned int uSrcData = 0x12345678;

    cout << hex << "\n\nuSrcData = 0x" << uSrcData << endl;
    Data1 d2;
    d2.bit0 = uSrcData >> 31;
    d2.bit1 = (uSrcData >> 28);
    d2.bit2 = (uSrcData >> 22);
    d2.bit3 = (uSrcData);

    cout << hex << "bit0 = 0x" << d2.bit0 << endl;//0x0
    cout << hex << "bit1 = 0x" << d2.bit1 << endl;//0x1
    cout << hex << "bit2 = 0x" << d2.bit2 << endl;//0x8
    cout << hex << "bit3 = 0x" << d2.bit3 << endl;//0x345678
}
```

对位字段进行合适的操作，可以方便地取出无符号数中我们想要的内容。

分支地址表：在数据区存储多分支的起始地址。当遇到多分支结构时，在这部分进行寻址。这样可以减少分支语句数。

计算机硬件对过程的支持：比如ra(x1),a0-a7(x10-x17)这些寄存器。

栈指针sp(x2)

x5-x7及x28-x31为t0-t6

x8-x9及x18-x27为s0-s11

如果一个过程不调用其他的过程，那么我们称这个过程为叶子过程。如果在嵌套过程中，那么我们就需要将必要保存的寄存器进行压栈，调整sp.

x3(gp)的作用：为了简化对静态数据的访问，**部分**RSICV保留x3用作全局指针。

栈也会为局部变量分配空间。我们把保存有寄存器和存储有局部变量的段称为过程帧或者活动记录。有些编译器使用fp(x8)用作帧指针。指向帧的第一个字。如果对sp处理得好也许可以不用这一点。

栈从用户地址空间的高端开始。低端内存的第一部分为保留区。第二部分为代码区。第三部分为静态数据区。第四部分为堆区。也就是说，栈和堆是**相向**生长的，这样有利于对内存的高效利用。C调用malloc和free来分配空间或者释放空间。

RSICV中，栈空间从0x0000 0x3f ffff fff0开始向下；代码从0x0000 0000 0040 0000 开始向上。静态数据区从文本段末开始。

尾调用具有高效的迭代。

ASCII码对人类非常友好。但是java中，为了更有包容性，其默认采用unicode编码。其默认采用16位表示一个字符。riscv保持16字节栈空间对齐。

RSICV中的寻址模式，无非是立即数寻址，寄存器寻址，基址寻址（寄存器加常量）和PC相对寻址四种。条件分支只能到达附近的区域。

### 并行

如果并行执行的任务之间不相互同步，就存在数据竞争的风险。并行机制依赖于硬件提供的同步指令。

在互斥区中的数据，只有单个处理器可以操作。

RSICV中对并行的支持指令：lr.w（保留加载）和sc.w（条件存储）等。这两条指令要顺序使用。也就是先进行保留加载，再进行条件存储。如果保留加载的目标地址，在条件存储执行之前，其中内容发生了变化，那么就不会成功。sc.w有三个寄存器参数。第一个rd用于表征存储成功还是失败，值为1或0。rs1指定存储的内容，rs2指定地址。利用这两个指令，可以实现原子交换。这样的操作可以构建更多的原子操作。要想获得锁变量，我们也需要进行原子的操作。但是，释放的时候就随意了。

### 翻译

首先通过编译器。编译器的作用，就是把高级语言转换为汇编语言。

然后通过汇编器。汇编器的作用是对伪指令进行转换。转换为RISCV中的基本指令,并且生成二进制机器码，生成目标文件。在汇编器中，对符号表和指令位置进行了很好的维护，从而进行汇编。

接下来通过链接器。链接器的作用是将目标代码和目标库之间进行连接缝合。链接器会将代码和数据模块按照符号特征一起放入内存，重写数据和指令标签的地址，最后修正目标文件中的内部引用以及外部引用。从而生成可执行文件。可执行文件和目标文件的格式是相同的，但是目标文件中可能有未解析的引用。

在运行时，需要加载器进行工作。加载器会把可执行文件加载到内存中并启动之。

除去静态链接库，还有一种链接方式是使用动态链接库(DLL)。这是因为静态链接库可能很大，并且在库代码更新后，原程序并不会实时更新，需要重编译等操作。

起初的DLL，是运行一个动态的链接程序，使用额外的信息来查找相应的库并更新外部引用，但是它还是链接了所有可能的例程。DLL的延迟过程链接版本改良了这一点。当需要一个DLL中的程序时，程序会调用一个虚入口。它会加载一个表示目标例程的编号，然后到达动态链接器或者加载器。由其找到所需例程，并且修改虚入口之后的跳转地址。在后续对这个相同例程的调用时，操作系统会使用虚拟内存进行管理，之后不必再执行重映射操作。

曾经，指针自增比数组的效率更高，因为加法比乘法方便。但是现在的编译器可以帮我们做这些内容了。

ARM：最流行的嵌入式设备使用的架构。

ARM是另外一种与RISCV相类，但组成很不同的架构。它具有更多的寻址方式，并且有传统的四位条件码：负，零，进位，溢出。

ARM中的12位立即数：字段低8位零扩展为32位值，然后循环右移。移位次数是字段高四位指定的数字乘2。

循环右移：将最右侧的值右移至首位。

ARM支持保存一组寄存器。称为块加载和块存储等。

x86一直在不断更新。1985年发布了80386.但是通用寄存器只有8个。

x86存在一种很特殊的寻址方式，暂称之为比例下标寻址好了。即$基址+2^{比例}\times 下标，比例\in\{0,1,2,3\}$

x86的整数运算中存在数据传送指令，比如move, push, pop等指令。其亦存在字符串指令，包括字符串传送和字符串比较等。push和pop能够把数据在栈中进行读取。x86中甚至存在loop这种循环指令，也存在inc,dec等自增，自减指令。

RISCV中基本结构的剩余指令:slt, sltu, slti, sltiu, auipc.

auipc很合适于在动态链接库中使用。

Python 的解释器性质决定了性能不会比C 的编译器好。

## 算术运算

### 加减法

在计算机中，减法显然可以通过加法进行计算。实现加法和减法的硬件是ALU.

有的加法器存在**饱和**，即超出最大上限时，为最大值；低于最低下限时，为最小值。

#### 超前进位

关键无论输入何时改变，硬件总会并行执行。考虑$a+b$，则：

$$
c_{i+1}=(b_i\cdot c_i) +(a_i\cdot c_i) +(a_i\cdot b_1)
$$

这无非是在描述只要有两个是1，就得进位。上式也可以写成：

$$
c_{i+1}=(a_i+b_i)\cdot c_i+(a_i\cdot b_i)
$$

我们定义：

$$
g_i=a_i\cdot b_i\\
p_i=a_i+b_i
$$

从而，上式可以写成：

$$
c_{i+1}=g_i+p_i\cdot c_i
$$

g表示generate，p表示propagate.也就是说，只要$g_i=1$,那么一定会产生进位。如果$p_i=1$，那么一定可以把上一位的进位传递下去。

然后，我们可以把几个带有超前加法的位加法器捆在一起。把多组这样的捆绑捆在一起，可以得到一个更大的超前进位加法器。

### 乘法

最平凡的方式：被乘数用双倍空间存，乘数用正常空间存。每次周期乘法结束后，被乘数左移一位，乘数右移一位。每次仅考察乘数的最后一位。这样，只需要把被乘数和积之间作运算就可以了。

为了对硬件进行优化，我们可以充分利用双倍空间的积寄存器。我们可以把乘数储存在积寄存器中，每次同样只操作乘数的最后一位，结果加在积寄存器的高位上。每次对积寄存器进行右移。

带符号乘法是平凡的。我们只需要把符号先记录下来就好了。

还有一种方式，是我们可以考虑使用一堆加法器，组成一棵树的形状来加速这个过程。

### 除法

最简单的除法，那就是移位加减法。一开始把余数寄存器初始化为被除数。这很符合人类直觉，不复赘述。

改进版本是类似的。只不过能够优化下硬件罢了。就是把余数寄存器和商寄存器存储在了一起。

有符号的除法是类似的。

快速除法一般采用查表法来预测。通过余数后六位和除数前四位预测这一点。

### 浮点数运算

浮点数运算采取的是科学计数法。整数部分为1.形如：

$$
1.xxxxx...\times 2^{yyyy...}
$$

32位浮点数一位符号，8位指数，23位尾数。浮点数的特点是会产生上溢和下溢。对于64位浮点数，指数为11位，尾数为52位。

有的时候，发生上溢出或者下溢出会产生中断。

### IEEE 754的浮点数标准

如果一个浮点数的指数为0，但是尾数不是0，那么其表示的对象是正负非规格化的浮点数。如果指数位全为1，尾数位为0，那么我们用它表示正负无穷。如果指数位全为1，尾数不为0那么我们用它来表示非数(NaN)。

### 浮点数加法

把浮点数指数较小的数字的指数转化为和指数较大的浮点数相同。即将尾数进行右移。然后，将二者进行有效位数相加。然后，进行规格化。

### 浮点数乘法

平凡地，正如直觉那样，先把两个数字的指数相加。然后，将两个数字的尾数部分进行相乘，得到计算的结果，然后得到规格化的表示。

### 浮点数运算中的精确算术

在运算的过程中，会额外保留两个bit，这样在舍入的时候会更加精确。

### 子字并行

一个128位的加法器，也可以视作16个8位加法器。这种对短向量分割后，进行并行处理的方式可以提高处理的速度。  

### 一些常见问题

- 右移不等价于除以2的整数次幂。

- 浮点数加法不满足结合律。因为溢出！

## 处理器

### 时钟同步方法

采用沿边触发的时钟。这样，可以保证每个部件对状态的读取和修改具有同时性。

如果一个部件，并不是每一个时钟周期都会做出反应，那么我们需要额外采取一个控制信号，来控制信号的更新。我们用有效(asserted)来表示控制信号的高电平。反之，则表示低电平。

### 数据通路

数据通路单元：用于操作或者保存处理器中数据的单元。RISCV中，包括指令存储器、数据存储器、寄存器堆、ALU、加法器。

一般而言，寄存器堆需要有两个读端口（因为有不少指令一次要读两个寄存器中的内容）和一个写端口。这几个端口的导线都是5位的。此外，还有三根对应的数据线。它们都是32位的，用于传输数据。同时，寄存器堆需要有一个写控制信号。从而保证只在我们需要的上升（下降）沿进行写操作。

立即数生成单元，可以把指令中的一些立即数进行符号扩展，然后用于使用。这在存取指令中很常见。

在数据存储单元中，我们有一个地址输入，写数据输入和读数据输出。该单元，不可以同时执行两种指令。并且，它既需要一个读信号，也需要一个写信号。

分支指令判断：从寄存器堆中读取内容。判断分支是否成立。然后，选择对PC的操作方式。

可以通过多路选择器，将一些较为相近的结构进行复用。

小型的ALU控制单元：将机器码翻译成需要ALU进行的操作的译码。

主控制单元：首先，由于RISCV中的机器码具有一定的规律性，所以在处理时，数据通路得到了一定的简化。从而对硬件进行简化，甚至一定程度上加快了运行的速度。

指令格式固定的好处在于，可以直接把对应位置的编码强加到目标位置上，而无需考虑opcode。opcode起到的是控制线的作用。也就是说，将opcode加到主控单元中，然后由主控单元决定对每一个单元的控制。

### 数据通路的操作

#### R型指令的数据通路操作

1. 取出指令，PC自增。

2. 从寄存器中读出内容，主控制单元计算控制信号。

3. 根据操作码确定ALU功能，对读出的数据进行操作。

4. 将ALU结果写入目标的寄存器。

### 流水线

流水线不能提高单步骤的速度。但是，流水线可以提高系统的吞吐率，从而减少完成整个任务的时间。

RISCV指令执行通常包含五个步骤：取指令、读寄存器并译码、执行操作或者计算地址、访问数据存储器中的操作数、将结果写入寄存器。

现代x86架构中，x86指令的长度不同，为了方便进行处理，所以会将这样的指令转化为像RSICV中那样的简单指令进行处理。

理想状况下，流水线的加速应该是$\frac{ideal\ CPI}{number\ of\ pipe\ stages}$。但是这一般是达不到的。

我们记流水线下的加速为：

$$
\text{speedup}=\frac{(ideal\ CPI)\cdot (number\ of\ pipe\ stages)}{(ideal\ CPI)+(pipeline\ stall\ CPI)}
\cdot \frac{cycle_{unpiped}}{cycle_{piped}}
$$

前面一项，为是否在流水线下的CPI的比值。后一项，为时钟周期的比值。

### 流水线冒险

#### 结构冒险

硬件上的不支持。但由于RSICV是面向流水线设计的，所以这一点较为容易避免。

#### 数据冒险

一个步骤必须等待另一个步骤完成的情况。为了解决这个问题，我们采用称为前递(forwarding)或者旁路(bypassing)的方式来优化这一点。也就是说，在数据还没有被显式地写入寄存器中时，就将其传给目标指令。

对如load等指令而言，会造成流水线上更长时间的停顿，也就是为了处理载入-使用型数据冒险导致的情况。

#### 控制冒险

需要根据指令的结果做出决定。但是决定是否跳转的指令正在运行中。因此，我们一般采用预测的方式来处理条件分支。因为停顿这种解决方式太慢了。还有一种方式来解决这个问题，我们称之为延迟决定(delayed decision)。也就是说，我们把一些与分支无关的指令，放到计算跳转条件值之后进行。

### 流水线数据通路和控制

#### 指令的五个阶段

1. IF:取指令

2. ID:指令译码和读寄存器堆

3. EX:执行或计算地址

4. MEM:存储器访问

5. WB:写回

上述的五个过程是一次执行的。但是，存在两种反向的数据流动，可能会对后续指令的执行产生影响。它们是：

- 写回过程中，会对寄存器堆产生影响。

- 下一PC值会根据运算结果进行选择。

利用上升沿和下降沿，保持正确的时序。

可以前半周期写入，后半周期读入。

也就是说，我们可以把每一部分进行分离，后半周期读入，前半周期写入。每一个逻辑部件之间实现分离。

#### 流水线控制

类似之前的方式。利用不同的opcode，对不同的逻辑部件进行控制。比如说，我们考虑是否对内存进行读取，ALU将要执行的指令到底是个R指令还是个I指令，PC应当要变为何值等问题。这里我们可以使用一个MUX来解决这个问题。在这里，我们可以使用一个MUX来决定最终读取的内容。

### 前递与停顿

冒险的两对条件：

- 运算结果储存对象为运算数之一。

- 访存结果储存对象为运算数之一。

为了解决这些问题，我们可以使用前递单元来解决这个问题。也就是说，将运算所得结果通过前递单元递回，通过MUX决定最终采取哪一个数值。在前递单元中，我们可以选择三种状态：由寄存器堆取的内容；由ALU运算结果取得内容，由访存取得的内容。

#### 数据冒险与停顿

一种常见的解决方法，是通过插入一条空指令来解决这个问题。

#### 三种常见的数据依赖

- 写后读（WAR）

- 写后写（WAW）

- 读后写（RAW）

WAR是真实的数据依赖。剩下两个则是虚假的数据依赖。对于后两者，我们可以使用寄存器重命名的方式来解决。

### 控制冒险

解决分支跳转的方式有如下几种：

- 假设分支不发生

- 缩短分支延迟

- 使用动态分支预测器

第二点，是通过汇编代码移动的方式实现的。

对于分支预测器，比较常见的实现方式是分支预测缓存，或者分支历史表。

目前，比较好的分支预测器是相关预测器，也就是同时利用该分支以及近期全局分支来进行预测。另一种比较好的预测器是锦标赛分支预测器。也就是一个分支给出多个预测，然后通过一定的选择机制来进行挑选。

### 例外和中断

例外，指的是意外的控制流变化，指的是无需区分来源于处理器内还是处理器外的控制流变化；中断，则一定是处理器外部引发的。

对于例外的处理，一般会在系统例外程序计数器中保存发生例外的指令地址(SEPC)，然后把控制权移交给操作系统。为了说明到底是什么原因，我们需要把原因存入系统例外原因寄存器(SCAUSE)。或者，采用向量式中断方式。也就是说，在向量式中断内存区域的基础上，再加上一个对应的例外值，将该值作为例外的表示。

我们可以把例外处理看做是一种特殊的控制冒险。

在遇到分支预测失败的情况下，我们要清除取指阶段的指令和译码阶段的指令。并且，我们应当给出新的信号，控制EX、WB等阶段输出恒为0.

### 指令间的并行性(ILP,instruction-level parallelism)

#### 数据依赖的种类

- 真数据依赖

- 名称依赖

- 控制依赖

如果指令$j$会用到指令$i$中的指令，或者指令$j$会依赖的指令$k$依赖于指令$i$，那么我们称指令$j$依赖于指令$i$.

真数据依赖，指的是确实完全不能交换顺序的两条指令。它们之间具有数据流动。

名称依赖，指的是两条指令使用了相同的寄存器名称或者地址等。但是，二者之间并没有任何的数据流动关系。比如读后写就是一种名称依赖，读后写又称为反依赖。同样的，还有写后写也是一种名称依赖，称为输出依赖。

三种数据冒险：

- 写后写

- 写后读

- 读后写

控制依赖：保证分支前语句不可出现于分支中。分支中语句不可外提到分支前。

我们也需要保证数据流中数据的正确性。对数据流进行分析，我们也可以找出死代码。

#### 流水线调度和循环展开

对于独立的指令，我们可以将它们进行调度，从而减少停顿的可能。

如果一个循环中，所有的操作都是并行的，那么平凡地，我们可以把这个循环展开，使之能够并行地执行。

但是，在指令调度过程中可能产生寄存器紧缺的副作用。

#### 高级分支预测

##### 相关分支预测器

不仅和当前分支有关的预测器，我们称之为相关预测器。

$(m,n)$预测器利用的是最近$m$个分支的行为，总共有$2^m$个分支预测器，每一个分支预测器都是$n$位的。

这在硬件上是易于实现的。我们可以做一个$m$位的移位寄存器来记录最近$m$个分支的行为。我们把分支地址的低四位和这$m$位拼接在一起，作为一个索引。这样的六位索引可以用来寻址

##### 竞争预测器

在全局预测器和局部预测器之间竞争。由分支地址决定使用的局部预测器，由分支历史决定选择的全局预测器。由分支地址和分支历史共同决定选择的是哪一种寄存器。

##### 带标签的混合预测器

有多个不同的预测表，每一个表对应着不同的分支历史数目。它们共同作用，得到结果。

#### 动态调度

通过乱序执行来减少停顿。这样会引入一个问题：如果产生异常，异常发生时处理器状态可能与按照顺序执行时的情况不一致，导致非精确异常的产生。

#### Tomasulo

寄存器重命名可以解决WAW和WAR的问题。在这里，我们使用保留站来进行寄存器重命名。

Tomasulo中指令的三个过程：发射，执行，写回。

保留站中一条指令的组成部分：busy,op,q1,q2,v1,v2,a

Tomasulo的优势

- 一条指令计算完成后，可以同时使多条指令处于可执行状态。

- 消除了除真数据冒险外的冒险情况。

在对内存进行读写的时候，我们需要检查载入指令和读取指令的地址是否重合。如果重合，那么就不可以这么做。

Tomasulo的关键是乱序执行，顺序提交。因此，指令在最后会进入重排序缓冲区结构。在这里，指令的结果会被顺序提交。

指令执行的四个步骤：

- 发射。要求ROB和RS中都有空位。

- 执行。如果有操作数不可用，那么在等待计算的过程中需要监视CDB。在这里，检查RAW冒险。在这一步，存储只需要计算目标地址即可。只有在commit的时候，我们才需要真正地把这个地址写入。但是对于载入而言，没有办法，我们必须得把这个数据真正地读出来。

- 写结果。对于每个单元而言，如果结果计算完成，那么就将它写到总线CDB上。每一个保留站都需要监听CDB上的信息，然后再更新对应的ROB中的信息。

- 提交。提交有三种类型。对于存储提交而言，我们需要将对应的数据切实地写回到存储器中。对于预测错误的提交而言，我们需要清空一切正在执行的指令。然后重新恢复原状。对于其他的提交而言，我们只需要正常提交即可。

解决乱序执行过程中，存储器可能发生的数据冒险的方法：

- 如果存储的地址与读取的地址相同，那么不允许读取指令开始第二阶段（读取）。

- 计算载入指令的有效地址时，保持之前存储指令的顺序。

#### 多发射

多发射处理器主要有三种类型：

- 静态调度超标量处理器

- 动态调度超标量处理器

- VLIW（超长指令字）处理器

对于两种超标量处理器而言，每周期发射的指令数目是不固定的。但是，VLIW每周期发射的指令数是固定的。VLIW和静态调度超标量处理器都是依靠编译器进行的工作。静态调度超标量处理器常用在嵌入式（比如ARM架构）中。动态调度超标量处理器感觉是当下微机处理器的主流。VLIW则常见于信号处理中。

##### VLIW

VLIW的思想就是想要同时利用不同的部件，从而提高CPU的工作效率。因此，其会将可以同时发射的语句包装成一个大语句，一起发射出去。这样存在的问题是：为了提高并行度，不可避免的，需要进行循环展开等工作，这样会极大地提高代码的长度。此外，由于一条指令中，很可能有一部分处于空置状态，所以，代码的冗余程度也进一步加大。

##### 动态调度，多发射，推测

动态调度的Tomasulo架构，需要考虑如何发射，才能够保证原来代码的执行顺序正确。并且，各种总线的宽度也应该被拓宽。

有两种方式解决多发射的发射问题。第一种，是在时钟上升沿和下降沿各发射一次，但是这样每个周期至多执行两条指令；还有一种，则是采用额外的部件来解决这个问题。

简单而言，这个问题的解决方式分三步走：

- 检查有多少条指令可能被发射，为所有的这些指令预留保留站中的位置。

- 检查发射的指令之间相互的依赖关系。

- 更新依赖表项。

#### 关于指令交付和带宽

##### 分支目标缓冲区

简单的说，这一部分提供了一个hashmap，其为当前PC到预测PC和预测分支结果的一个映射。每次取指到当前PC，可以查询其是否在缓冲区中。如果在，那么我们可以根据预测结果去进行更新PC，并且去取指令。如果不在，那么我们可以判断当前PC对应的语句是否为分支指令。如果是，我们则将其添加到缓冲区中。

#### 专用分支预测器

过程返回预测。也就是说，额外开启一个栈，来存储call时存放的地址。每次有return时，取出栈顶，然后弹栈。以栈顶元素作为返回的预测值。

#### 集成取指单元

这是为了满足多发射处理器对指令的需求。在这里，分支预测器被视作是集成取指单元的一部分。这一单元需要解决三个问题：

1. 集成分支预测。

2. 指令预取。

3. 指令存储器访问和缓存。

#### 推测

另一种实现寄存器重命名的方式：把结果先暂存在逻辑寄存器中。之后再搬运到物理寄存器中。这样做的好处，在于没有目标寄存器的指令，能够不占用逻辑寄存器。也就是说，在指令发射的同时，我们就把所有的指令进行了一次重写，直接对指令中使用和定义的寄存器进行重命名。

推测是具有代价的。尽管，对于简单指令而言，推测可以减少流水线停顿的可能。但是，如果遇到cache-miss等情况，一旦推测错误，它的时间成本是巨大的。因此，常见的做法是对其进行等待，直到该指令的执行不再具有推测性为止。

我们也可以考虑同时对多个分支进行推测。这样做在分支频率很高的时候是合理的。但目前来看，这样做的性价比并不是很高。

我们认为，推测会提高能耗。这是预测错误导致的问题。因此，目前的解决思路是想办法减少错误的推测，或者只在预测准确度高的地方进行预测。

地址别名预测可以提高载入、存储指令的效率。但是，目前还没有什么诱人的成果。

#### 多线程

多个线程共享单个处理器的功能单元。线程切换的开销远小于进程切换。

目前主要有三种方式来实现多线程。

- 细粒度多线程(fine-grained multithreading)

- 粗粒度多线程(coarse-grained multithreading)

- 同时多线程(simultaneous multithreading, SMT)

细粒度多线程，指的是每个时钟周期都会发生线程间的切换。所有停顿的线程都会被跳过。因此，当一个线程停顿时，我们可以执行另一个线程的指令。这种方式是减缓了单条指令的执行速度，但是提高了多线程的吞吐量。

粗粒度多线程，指的是在发生成本较高的停顿时，才发生线程切换。比如cache-miss.

同时多线程，首先也可以隐藏长延迟事件造成的延迟。但是，其可以通过寄存器的重命名和动态调度来执行不同线程的多条指令。

## 存储器

### 局部性原理

- 时间局部性：刚刚用过的某个数据项可能会在不久后被再次访问。

- 空间局部性：刚刚被访问的某个数据项，和它相邻的数据项也可能会在不久后被访问。

因此，根据局部性原理，我们可以用它来构建层次化的存储结构。

越快的存储器越靠近处理器，它的容量也越小，价格也越高。最后一层的存储器，在微机中一般是磁盘。它里面放有**所有**数据。

在层次化存储中，数据是一层一层流动的。数据要从第三层转移到第一层，必须先到第二层。并且，在相邻两层之间进行信息交换，是有一定的最小单元的。我们称之为块，或者行。

我们称数据在本层存储中找到为"hit"，没有找到为"miss"，命中率(hit rate)就是hit占访问该层总次数的比率。失效率(miss rate)则自然地，与之相反。 

**命中时间**：访问某一层数据所需要的时间。包括判断是否命中。

**失效损失**：把数据块从下层存储器复制到某层所需的存储器，并且将其返回给处理器所需的时间。

### 存储技术

目前，主流的四种层次化存储技术为：

- 静态随机访问存储(SRAM)(0.5-2.5ns)

- 动态随机访问存储(DRAM)(50-70ns)

- 闪存(flash memory)(5000-50000ns)

- 磁盘(magnetic disk)(5000000-20000000ns)

四种类型从上到下，它们的访问时间逐步增大，但是成本也随之下降。

#### SRAM

SRAM是一种简单的集成电路。对于任意位置的数据，SRAM访问时间固定。这是因为它不需要定期刷新电路，而是用6-8个晶体管存储一个bit。它的访问时间和两次存储访问的间隔周期时间接近。因此，在SRAM中，只要不断电，数据会被一直保存。

曾经，SRAM芯片都是作为独立的高速缓存芯片。目前，这些高速缓存都已经被集成到了处理器上。

#### DRAM

DRAM中，用电容来存储数据，并且用单个晶体管来访问电容中存储的电荷。在DRAM中，一个晶体管就存储着一个bit，所以它的存储密度更高。但也正因为这一点，所以DRAM中不可以长期保持数据，需要进行周期性的刷新，因为电容会缓慢地进行放电。因此，我们称之为动态。刷新的做法是：一个读周期，然后跟一个写周期。

多个这样的晶体管-电容结构堆在一起，就组成了cell阵列。在cell阵列中，cell排布成正方形。每一行共享一根word line，控制晶体管开关的接通与否；每一列共享一根bit line，用于读取电容中的内容。

然后，将这些阵列封装在一起，就得到了bank。它们共享同一组word line和bit line。

在bank中，我们将其分为一系列row。在当前的DRAM中，row也会被缓冲。目前，为了更加高效，我们会为每个bank准备对应的行缓冲。

此外，为了优化和处理器的接口，有一种称为SDRAM（同步DRAM）的结构，从而消除了内存和处理器之间的同步问题。这样做有利于突发传输(burst transfer)。也就是说，不再每个周期均指定待读取的地址，而是在某个周期开始时指定起始地址，突发类型，突发长度。然后，在每个周期时均返回其需要的数据。这是由周期的同步性保证的。

更快的DRAM：双倍数据传输率(DDR)SDRAM.也就是说，在时钟周期上升沿和下降沿，其都会传输一次数据。

服务器的存储通常会集成在电路板上。这被称作双列直插式内存模块(Dual Inline Memory Modules, DIMM)。DIMM中可以有多个DRAM芯片，我们称这个芯片的集合为rank。

#### 闪存

闪存是一种电可擦除的，可编程的只读存储器(Electrically Erasable Programmable Read-Only Memory, EEPROM)。闪存的写操作会对闪存本身造成磨损。因此，闪存中存在一个控制器，来将发生多次写的数据块重新映射到写的较少的数据块中，使得写操作尽量分散。这种技术被称作耗损均衡。

闪存比较坚固，更加适合于移动设备。

#### 磁盘

磁盘由盘片组成，它们每秒旋转约5400-15000周。它们的每一面上都由磁性材料进行覆盖。在盘面的上方，有一个被称为读写头的小型电磁线圈。磁盘表面可以分成上万个同心圆，我们称之为磁道(track)。磁道按顺序，划分为上千个可以保存信息的扇区(sector,磁道上的一段)。每个盘面都配有一个磁头，它们互相连接，并且一起移动。每个磁头都可以读取每个盘面的每一条磁道。柱面(cylinder)表示某磁头在某一点处可以访问到的所有磁道的集合。

操作系统对磁盘数据的访问如下：

- 把磁头定位到正确的磁道上方。这称为寻道(seek)。所需的时间称为寻道时间(seek time).

- 然后，我们需要等待所需扇区旋转到读写磁头下。这段时间被称为旋转延时(rotational delay).

- 然后，我们要进行数据的传输。这一部分时间为(transfer time).

磁盘为了提高性能，也会进行一定的缓冲。

磁盘没有写损耗。

#### cache基础

cache的使用原理：如果处理器需要一个数据，会在cache中进行查找。如果cache中不存在这个元素，那么会产生一次cache miss。随后，会在内存中对该数据进行读取，并将这个数据读取到cache中。  

##### 直接映射cache

比较常见的直接映射cache，就是采用$块地址\text{ mod }cache_{size}$进行标记。但是，这样很明显，不同的数据块可能会存储于同一个cache位置中。因此，为了解决这个问题，直接映射cache中，每一个存储数据块上需要存储一组标签，其保存了必要的地址信息。标签只需要存储块的高位地址就足够了。同时，为了验证存储的有效性，我们也需要添加一个有效位，用以表示这个数据是否有效。

cache初始化为空，所有的有效位都会被标记成无效。

对于所有要去访问的地址，我们可以将其分为标签字段和索引字段和字节偏移量。索引字段，用于查找cache中对应的数据块。标签字段，用来和cache中的标签位进行比较。字节偏移量，用来取出对应的数据。如果有cache中有$2^n$个数据块，那么我们就需要$n$位作为索引字段。如果数据块的大小为$2^m$个word，那么我们就需要在数据块中使用$m$位来确定单字，并且用最后两位来确定word(4 bytes)中的字节偏移量。容量更大的块，cache的失效率会降低。但是，这样一来，对空间局部性的利用也下降（因为失效损失会增大），导致cache失效所带来的好处有所减少。同时，如果在cache大小不变的情况下，cache快大小过大，失效率也会提高。

为了尽量减少失效损失所带来的影响，所以我们需要想办法解决这个问题。

- 提早重启(early restart)：只要数据块中我们所需的数据返回了，就立刻继续执行。然后，我们再慢慢地把数据写入cache。

- 关键字先行(critical word first)：让所需的数据先传输到cache中，再慢慢传输数据块中的剩余数据。效果略好于提早重启，但也有着相同的问题。

##### cache失效处理

如果cache命中，那么我们返回或是修改数据就好了。没有必要去做更多工作。但如果cache失效了，那么我们必须要做更多的工作。cache失效，会引发流水线一定的停顿。失效后的处理，简单地说，就是把数据从内存读到cache中，然后，再次执行cache中的读写操作。这一次会在cache中命中。然后继续处理。

##### cache写操作

如果每次对cache中的数据进行修改时，我们不将其直接写到主存中，那么cache和主存则是不一致的。为了保持cache和主存一致，一种简单的方式是在cache修改后，直接将数据写回内存。这种方式被称为写穿透(write-through)。如果发生了写失效，按照写穿透的思路，我们也从主存中取出数据，将其写入cache，然后再将其写回。这种方式简单，但是效率比较低。

一种稍好的解决方式是使用写缓冲(write buffer)，其中保存着等待写回主存中的数据。也就是说，数据在写入cache的同时也同时写在缓冲中。缓冲中慢慢地将数据写入主存。如果缓冲区满了，那么处理器也不得不停顿，直到缓冲区中重新出现空位。

还有一种性能更好的策略，那就是写返回(write-back)。更新的数据只会被写在cache中。只有当数据被替换出cache时，才会被写到下一级存储之中。但是，这种策略的实现也会复杂不少。

##### 写失效和写返回的处理

在写穿透中，cache的实现主要有这两种：

- 写分配：把数据从内存取到cache中，改写数据块中的对应数据。

- 写不分配：直接在内存中改写对应的数据。

#### cache性能

$$
CPU时间=(CPU执行周期数+等待存储访问的时钟周期数)\\ \times 时钟周期\\
读操作带来的停顿周期数=\frac{读操作数目}{程序}\times读失效率\times 读失效代价\\
\\
写操作带来的停顿周期数=\frac{写操作数目}{程序}\times写失效率\times 写失效代价\\
+写缓冲满时的停顿周期\\
等待存储访问的时钟周期数=\frac{指令数目}{程序}\times\frac{失效次数}{指令数目}\times 写失效代价\\
+写缓冲满时的停顿周期
$$

平均存储访问时间(AMAT)用来衡量cache的设计。定义为：

$$
AMAT=命中时间+失效率\times失效代价
$$
